{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing testingData/page1...\n",
      "Processing testingData/page94...\n",
      "Processing testingData/page56...\n",
      "Processing testingData/page6...\n",
      "Processing testingData/page18...\n",
      "Processing testingData/page76...\n",
      "Processing testingData/page81...\n",
      "Processing testingData/page26...\n",
      "Processing testingData/page86...\n",
      "Processing testingData/page32...\n",
      "Processing testingData/page7...\n",
      "Processing testingData/page49...\n",
      "Processing testingData/page25...\n",
      "Processing testingData/page52...\n",
      "Processing testingData/page38...\n",
      "Processing testingData/page80...\n",
      "Processing testingData/page15...\n",
      "Processing testingData/page93...\n",
      "Processing testingData/page22...\n",
      "Processing testingData/page5...\n",
      "Processing testingData/page78...\n",
      "Processing testingData/page20...\n",
      "Processing testingData/page98...\n",
      "Processing testingData/page92...\n",
      "Processing testingData/page30...\n",
      "Processing testingData/page37...\n",
      "Processing testingData/page97...\n",
      "Processing testingData/page96...\n",
      "Processing testingData/page40...\n",
      "Processing testingData/page63...\n",
      "Processing testingData/page55...\n",
      "Processing testingData/page73...\n",
      "Processing testingData/page89...\n",
      "Processing testingData/page53...\n",
      "Processing testingData/page21...\n",
      "Processing testingData/page79...\n",
      "Processing testingData/page70...\n",
      "Processing testingData/page43...\n",
      "Processing testingData/page35...\n",
      "Processing testingData/page66...\n",
      "Processing testingData/page72...\n",
      "Processing testingData/page64...\n",
      "Processing testingData/page41...\n",
      "Processing testingData/page88...\n",
      "Processing testingData/page45...\n",
      "Processing testingData/page50...\n",
      "Processing testingData/page83...\n",
      "Processing testingData/page16...\n",
      "Processing testingData/page14...\n",
      "Processing testingData/page68...\n",
      "Processing testingData/page74...\n",
      "Processing testingData/page85...\n",
      "Processing testingData/page8...\n",
      "Processing testingData/page3...\n",
      "Processing testingData/page59...\n",
      "Processing testingData/page60...\n",
      "Processing testingData/page90...\n",
      "Processing testingData/page99...\n",
      "Processing testingData/page9...\n",
      "Processing testingData/page62...\n",
      "Processing testingData/page23...\n",
      "Processing testingData/page28...\n",
      "Processing testingData/page95...\n",
      "Processing testingData/page58...\n",
      "Processing testingData/page47...\n",
      "Processing testingData/page10...\n",
      "Processing testingData/page34...\n",
      "Processing testingData/page51...\n",
      "Processing testingData/page27...\n",
      "Processing testingData/page24...\n",
      "Processing testingData/page33...\n",
      "Processing testingData/page91...\n",
      "Processing testingData/page29...\n",
      "Processing testingData/page44...\n",
      "Processing testingData/page31...\n",
      "Processing testingData/page54...\n",
      "Processing testingData/page17...\n",
      "Processing testingData/page39...\n",
      "Processing testingData/page77...\n",
      "Processing testingData/page71...\n",
      "Processing testingData/page2...\n",
      "Processing testingData/page61...\n",
      "Processing testingData/page67...\n",
      "Processing testingData/page36...\n",
      "Processing testingData/page46...\n",
      "Processing testingData/page11...\n",
      "Processing testingData/page75...\n",
      "Processing testingData/page100...\n",
      "Processing testingData/page48...\n",
      "Processing testingData/page69...\n",
      "Processing testingData/page4...\n",
      "Processing testingData/page84...\n",
      "Processing testingData/page82...\n",
      "Processing testingData/page57...\n",
      "Processing testingData/page13...\n",
      "Processing testingData/page12...\n",
      "Processing testingData/page42...\n",
      "Processing testingData/page65...\n",
      "Processing testingData/page19...\n",
      "Processing testingData/page87...\n",
      "Number of files Processed 100\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import cgi\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "def loadIntoPatternsStore(patternsStore, line):\n",
    "    components = line.split(\"\\t\")\n",
    "    groupId = components[0]\n",
    "    websiteName = components[1]\n",
    "    patternType = components[2]\n",
    "    missed = int(components[3])\n",
    "    junk = int(components[4])\n",
    "    total = int(components[5])\n",
    "    leftPattern = components[6]\n",
    "    rightPattern = components[7]\n",
    "\n",
    "    if groupId in patternsStore:\n",
    "        (websiteName, patternType, missed, junk, total, patterns) = patternsStore[groupId]\n",
    "        patterns.append((leftPattern, rightPattern))\n",
    "    else:\n",
    "        patternsStore[groupId] = (websiteName, patternType, missed, junk, total, [(leftPattern, rightPattern)])\n",
    "def readProductPatternStore(fileLocation):\n",
    "    patternsStore = {}\n",
    "    index=0\n",
    "    with open(fileLocation) as f:\n",
    "        for line in f: \n",
    "            if index==0:\n",
    "                index=1\n",
    "                continue\n",
    "            line = line.strip() #or some other preprocessing\n",
    "            loadIntoPatternsStore(patternsStore, line)\n",
    "#             print(\"line is \" + line)\n",
    "    output = []\n",
    "    for (k, v) in patternsStore.items():\n",
    "        output.append(v)\n",
    "    return output\n",
    "# patternsStore = readProductPatternStore(productPatternsLocation)\n",
    "\n",
    "\n",
    "\n",
    "def loadRelationIntoPatternsStore(patternsStore, line):\n",
    "    components = line.split(\"\\t\")\n",
    "    groupId = components[0]\n",
    "    websiteName = components[1]\n",
    "    patternType = components[2]\n",
    "    missed = int(components[3])\n",
    "    junk = int(components[4])\n",
    "    total = int(components[5])\n",
    "    leftPattern = components[6]\n",
    "    middlePattern = components[7]\n",
    "    rightPattern = components[8]\n",
    "\n",
    "    if groupId in patternsStore:\n",
    "        (websiteName, patternType, missed, junk, total, patterns) = patternsStore[groupId]\n",
    "        patterns.append((leftPattern, middlePattern, rightPattern))\n",
    "    else:\n",
    "        patternsStore[groupId] = (websiteName, patternType, missed, junk, total, [(leftPattern, middlePattern, rightPattern)])\n",
    "\n",
    "\n",
    "def readRelationPatternStore(fileLocation):\n",
    "    patternsStore = {}\n",
    "    index=0\n",
    "    with open(fileLocation) as f:\n",
    "        for line in f: \n",
    "            if index==0:\n",
    "                index=1\n",
    "                continue\n",
    "            line = line.strip() #or some other preprocessing\n",
    "            loadRelationIntoPatternsStore(patternsStore, line)\n",
    "#             print(\"line is \" + line)\n",
    "    output = []\n",
    "    for (k, v) in patternsStore.items():\n",
    "        output.append(v)\n",
    "    return output\n",
    "\n",
    "def mergePatternsGroup(p1, p2, p3):\n",
    "    p1.extend(p2)\n",
    "    p1.extend(p3)\n",
    "    return p1\n",
    "            \n",
    "def writePatternsToFile(fileLocation, productPatterns):\n",
    "    header = \"GroupId\\tWebsiteName\\tPatternType\\tMissed\\tJunk\\tOutof\\tLeftPattern\\tRightPattern\"\n",
    "    groupId = 1\n",
    "    output = []\n",
    "    output.append(header)\n",
    "    for (website, pType, missed, junk, total, patterns) in productPatterns:\n",
    "        rowPrefix = str(groupId) + \"\\t\" + website + \"\\t\" + pType\n",
    "        rowPrefix+=\"\\t\" + str(missed) + \"\\t\" + str(junk) + \"\\t\" + str(total)\n",
    "        for (l, r) in patterns:\n",
    "            row = rowPrefix + \"\\t\" + l + \"\\t\" + r\n",
    "            output.append(row)\n",
    "        groupId+=1\n",
    "#     print(\"output is \")\n",
    "#     for item in output:\n",
    "#         print(item)\n",
    "    writeListToFile(fileLocation, output)\n",
    "    print(\"Output written at location: \" + fileLocation)\n",
    "    \n",
    "    \n",
    "def writeListToFile(loc, l):\n",
    "    with open(loc, 'w') as f:\n",
    "        for item in l:\n",
    "            f.write(item+\"\\n\")\n",
    "\n",
    "def doProcessingWithoutClass(s, regExpIn, regExpOut):\n",
    "    allManaged =  re.sub(regExpIn, regExpOut, s)\n",
    "    removeQuoteIn = r'\"[^\"]*\"'\n",
    "    removeQuoteOut = r'\"\"'\n",
    "    return re.sub(removeQuoteIn, removeQuoteOut, allManaged)\n",
    "\n",
    "\n",
    "# def doProcessingWithoutClass(s):\n",
    "#     i = \"class[\\s]*=[\\s]*\"\n",
    "#     o       = \"class=\"\n",
    "#     s = re.sub(i, o, s)\n",
    "#     i = \"([^class])=\\\"[^\\\"]*\\\"\"\n",
    "#     o = \"\\\\1=\\\"\\\"\"\n",
    "#     return re.sub(i, o, s)\n",
    "\n",
    "#read the page from pageLocation\n",
    "def readPage(pageLocation):\n",
    "    htmlPageContent = \"\"\n",
    "    with open(pageLocation, 'r') as myfile:\n",
    "        htmlPageContent = myfile.read().strip()\n",
    "    return htmlPageContent\n",
    "\n",
    "\n",
    "#remove elements which were actually tag\n",
    "def isTag(s):\n",
    "    if s.find(\"<\")!=-1 and s.find(\">\")!=-1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#preprocess results before writing it to file\n",
    "def preprocessResults(output):\n",
    "    result = []\n",
    "    for o in output:\n",
    "        if isTag(o):\n",
    "            continue\n",
    "        result.append(o)\n",
    "    return result\n",
    "\n",
    "#document processing logic at this stage is about removing multiple whitespaces into single one \n",
    "def preprocessDocument(document):\n",
    "    return ' '.join(document.split())\n",
    "\n",
    "\n",
    "\n",
    "#Pattern is (l, r) and match them to htmlPageContent\n",
    "def findEntitySetwrtPattern(htmlPageContent, (l, r)):\n",
    "    #for each start location of pattern find its end\n",
    "    #for each end page find the pattern right\n",
    "    #extract everything till that point\n",
    "    #after extraction move one point above that pattern string\n",
    "    results = []\n",
    "    for m in re.finditer(re.escape(l), htmlPageContent):\n",
    "        start = m.start()\n",
    "        end = m.end()\n",
    "        rightPage = htmlPageContent[end:]\n",
    "        rightLoc  = rightPage.find(r)\n",
    "        if rightLoc==-1:\n",
    "            break\n",
    "        element = rightPage[:rightLoc]\n",
    "        if len(element)>1 and len(element)<300:\n",
    "            results.append(element)\n",
    "    return set(results)\n",
    "\n",
    "def createRegExpFromWordStr(wordsStr):\n",
    "#     wordsStr = getWordsStr(words)\n",
    "#     print(\"wordsstr is \" + wordsStr)\n",
    "    return (\"(\" + wordsStr +\")[\\s]*=[\\s]*\\\"([^\\\"]*)\\\"\", \"\\\\1=\\\\2\")\n",
    "\n",
    "def getRegExpForMatch(patternType):\n",
    "    words = patternType.split(\"_\")\n",
    "    wordStr = words[1]\n",
    "    return createRegExpFromWordStr(wordStr)\n",
    "\n",
    "def extractSet(patterns, htmlPageContent):\n",
    "    output = []\n",
    "    for pattern in patterns:\n",
    "        output.extend(findEntitySetwrtPattern(htmlPageContent, pattern))\n",
    "    return set(output)\n",
    "\n",
    "def applyPatternsToPageLocation(patternsStore, inputPageLocation, websitesPatternApplicable):\n",
    "#     patternsStore      = readProductPatternStore(patternsFileLocation)\n",
    "    plainPageContent   = preprocessDocument(readPage(inputPageLocation))\n",
    "    results = []\n",
    "    for pattern in patternsStore:\n",
    "        (websiteName, patternType, missed, junk, total, lrPatterns) = pattern\n",
    "        if patternType==\"plainPattern\":\n",
    "            pageContent = plainPageContent\n",
    "        else:\n",
    "            (regExpIn, regExpOut) = getRegExpForMatch(patternType)\n",
    "            noValuePageContent = doProcessingWithoutClass(plainPageContent, regExpIn, regExpOut)\n",
    "            pageContent = noValuePageContent\n",
    "        resultsPerPattern = preprocessResults(list(extractSet(lrPatterns, pageContent)))\n",
    "        if (len(resultsPerPattern)>0):\n",
    "            results.extend(resultsPerPattern)\n",
    "            if not websiteName in websitesPatternApplicable:\n",
    "                websitesPatternApplicable.add(websiteName)\n",
    "#             results.append((websiteName, resultsPerPattern, missed, junk, total))\n",
    "#         print(resultsPerPattern)\n",
    "    return list(set(results))\n",
    "\n",
    "\n",
    "#Pattern is (l, m, r) and match them to htmlPageContent\n",
    "def findRelationSetwrtPattern(htmlPageContent, (l, mid, r)):\n",
    "    #for each start location of pattern find its end\n",
    "    #for each end page find the pattern right\n",
    "    #extract everything till that point\n",
    "    #after extraction move one point above that pattern string\n",
    "    results = []\n",
    "    for m in re.finditer(re.escape(l), htmlPageContent):\n",
    "        start = m.start()\n",
    "        end = m.end()\n",
    "        rightPage = htmlPageContent[end:]\n",
    "        rightLoc  = rightPage.find(r)\n",
    "        if rightLoc==-1:\n",
    "            break\n",
    "        substr = rightPage[:rightLoc]\n",
    "#         print(\"substr is \" + substr)\n",
    "        mLoc = substr.find(mid)\n",
    "#         print(\"mloc is \" + str(mLoc))\n",
    "        if mLoc==-1:\n",
    "            continue\n",
    "        e1 = substr[:mLoc].strip()\n",
    "        e2 = substr[mLoc+len(mid):].strip()\n",
    "#         print(e1)\n",
    "#         print(e2)\n",
    "        if len(e1)>1 and len(e2)>=1 and len(e1)<100 and len(e2)<500:\n",
    "#             print(\"Appending \" + str((e1, e2)))\n",
    "            results.append((e1, e2))\n",
    "    return set(results)\n",
    "\n",
    "\n",
    "\n",
    "#input: all the pattern found and new html page\n",
    "#output: extract set of elements from the page that are in our set(whose definition we know)\n",
    "def extractRelationSet(patterns, htmlPageContent):\n",
    "    output = []\n",
    "    for pattern in patterns:\n",
    "        output.extend(findRelationSetwrtPattern(htmlPageContent, pattern))\n",
    "    return output\n",
    "\n",
    "#remove elements which were actually tag\n",
    "def isTagPair((a,b)):\n",
    "    if a.find(\"<\")!=-1 and a.find(\">\")!=-1 and b.find(\"<\")!=-1 and b.find(\">\")!=-1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#preprocess results before writing it to file\n",
    "def preprocessRelationResults(output):\n",
    "    result = []\n",
    "    for o in output:\n",
    "        if isTagPair(o):\n",
    "            continue\n",
    "        result.append(o)\n",
    "    return result\n",
    "\n",
    "\n",
    "def applyRelationPatternsToPageLocation(patternsStore, inputPageLocation, websitesPatternApplicable):\n",
    "#     patternsStore      = readProductPatternStore(patternsFileLocation)\n",
    "    plainPageContent   = preprocessDocument(readPage(inputPageLocation))\n",
    "    results = []\n",
    "    for pattern in patternsStore:\n",
    "        (websiteName, patternType, missed, junk, total, lmrPatterns) = pattern\n",
    "        if patternType==\"plainPattern\":\n",
    "            pageContent = plainPageContent\n",
    "        else:\n",
    "            (regExpIn, regExpOut) = getRegExpForMatch(patternType)\n",
    "            noValuePageContent = doProcessingWithoutClass(plainPageContent, regExpIn, regExpOut)\n",
    "            pageContent = noValuePageContent\n",
    "        resultsPerPattern = preprocessRelationResults(list(extractRelationSet(lmrPatterns, pageContent)))\n",
    "        if (len(resultsPerPattern)>0):\n",
    "            results.extend(resultsPerPattern)\n",
    "            if not websiteName in websitesPatternApplicable:\n",
    "                websitesPatternApplicable.add(websiteName)\n",
    "#             results.append((websiteName, resultsPerPattern, missed, junk, total))\n",
    "#         print(resultsPerPattern)\n",
    "    return list(set(results))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocessCategories(categories, productNames):\n",
    "    if \"Home\" in categories:\n",
    "        categories.remove(\"Home\")\n",
    "    if len(productNames)==1:\n",
    "        if productNames[0] in categories:\n",
    "            categories.remove(productNames[0])\n",
    "    return categories\n",
    "\n",
    "\n",
    "def getHtmlHeader():\n",
    "    return \"<html><head><style>\\nh1 {background-color:#C4C5F4;}\\n\\\n",
    "            ul{list-style: none;} \\n\\\n",
    "            li{text-align: center;}\\n\\\n",
    "            tr:nth-child(even) {\\n\\\n",
    "             background-color: #dddddd;\\n\\\n",
    "             }\\n\\\n",
    "            table, tr, td {\\n\\\n",
    "            border-collapse: collapse;\\n\\\n",
    "            border: 1px solid black;\\n\\\n",
    "            }\\n\\\n",
    "            #footer{\\n\\\n",
    "            background-color:#0493B2;\\n\\\n",
    "            text-align: center;\\n\\\n",
    "            position:fixed;\\n\\\n",
    "            bottom:0;\\n\\\n",
    "            left:0;\\n\\\n",
    "            height:25px;\\n\\\n",
    "            width:100%;\\n\\\n",
    "            }\\n\\\n",
    "            </style></head><body bgcolor=\\\"#DAF7A6\\\">\\n\\\n",
    "            <img src=\\\"htmlBlitData/beehyvLogo.png\\\" alt=\\\"Beehyv Technologies\\\" style=\\\"width:100%;height:200px;\\\">\"\n",
    "\n",
    "def getJavaScript():\n",
    "    return \"<script>\\n\\\n",
    "function myDisplayFunction(elt) {\\n\\\n",
    "    var x = document.getElementById(elt);\\n\\\n",
    "    if (x.style.display === \\\"none\\\") {\\n\\\n",
    "        x.style.display = \\\"block\\\";\\n\\\n",
    "    } else {\\n\\\n",
    "        x.style.display = \\\"none\\\";\\n\\\n",
    "    }\\n\\\n",
    "}\\n\\\n",
    "</script>\"\n",
    "\n",
    "\n",
    "\n",
    "def getHtmlFooter():\n",
    "    return \"<footer id=\\\"footer\\\"><font color=\\\"red\\\"><b>Powered by IIT BOMBAY</b></font></footer></body>\"+getJavaScript()+\"</html>\"\n",
    "\n",
    "\n",
    "def getTabularInfo(title, count, divId, items):\n",
    "    items = list(items)\n",
    "    output = \"<h1 onclick=myDisplayFunction(\\\"\"+divId+\"\\\")><font color=\\\"green\\\">\"+ title +\" (\" + count + \")</font>\"+\"</h1>\"\n",
    "    output+=\"<div id=\"+divId+\" style=\\\"display:none;\\\">\"\n",
    "    if len(items)==0:\n",
    "        output+=\"Failed to extract this section\"\n",
    "        output+=\"</div>\"\n",
    "        return output\n",
    "    output+=\"<table align=\\\"center\\\">\"\n",
    "    for (k, v) in items:\n",
    "        output+=\"<tr>\"\n",
    "        output+=\"<td><font color=#5F5BE7><b>\"+k+\"</b></font></td><td><font color=#5F5BE7><b>\"+v+\"</b></font></td>\"\n",
    "        output+=\"</tr>\"\n",
    "    output+=\"</table></div>\"\n",
    "    return output\n",
    "    \n",
    "\n",
    "\n",
    "def getHtmlSection(title, count, divId, items):\n",
    "    items = list(items)\n",
    "    output = \"<h1 onclick=myDisplayFunction(\\\"\"+divId+\"\\\")><font color=\\\"green\\\">\"+ title +\" (\" + count + \")</font>\"+\"</h1>\"\n",
    "    output+=\"<div id=\"+divId+\" style=\\\"display:none;\\\">\"\n",
    "    if len(items)==0:\n",
    "        output+=\"Failed to extract this section\"\n",
    "        output+=\"</div>\"\n",
    "        return output    \n",
    "    output+=\"<ul>\"\n",
    "    for item in items:\n",
    "        output+=\"<li background-color:><b><font color=#5F5BE7>\"+item+\"</font></b></li></br>\"\n",
    "    output+=\"</ul></div></hr>\"\n",
    "    return output\n",
    "\n",
    "def doExtraction(inputPageLocation):\n",
    "    patternsLocation = \"patterns\"\n",
    "    productNameLoc     = patternsLocation + \"/ProductPatterns.tsv\"\n",
    "    categoriesLoc      = patternsLocation + \"/categoryPatterns.tsv\"\n",
    "#     firstCategoriesLoc = patternsLocation + \"/firstCategories.tsv\"\n",
    "#     lastCategoriesLoc  = patternsLocation + \"/lastCategories.tsv\"\n",
    "    specLoc            = patternsLocation + \"/specs.tsv\"\n",
    "    firstSpecLoc       = patternsLocation + \"/firstSpecs.tsv\"\n",
    "    lastSpecLoc        = patternsLocation + \"/lastSpecs.tsv\"\n",
    "    relationLoc        = patternsLocation + \"/tablePatterns.tsv\"\n",
    "    productNamePatternsGroup = readProductPatternStore(productNameLoc)\n",
    "    categoriesPatternsGroup  = readProductPatternStore(categoriesLoc)\n",
    "#     catFirstPatternsGroup    = readProductPatternStore(firstCategoriesLoc)\n",
    "#     catLastPatternsGroup     = readProductPatternStore(lastCategoriesLoc)\n",
    "    specLocPatternsGroup     = readProductPatternStore(specLoc)\n",
    "    specFirstPatternsGroup   = readProductPatternStore(firstSpecLoc)\n",
    "    specLastPatternsGroup    = readProductPatternStore(lastSpecLoc)\n",
    "    relationsPatternGroup    = readRelationPatternStore(relationLoc)\n",
    "    websitesPatternApplicable = set([])\n",
    "    mergedCategoryGroup = categoriesPatternsGroup\n",
    "#     mergedCategoryGroup      = mergePatternsGroup(categoriesPatternsGroup, catFirstPatternsGroup, catLastPatternsGroup)\n",
    "    mergedSpecGroup          = mergePatternsGroup(specLocPatternsGroup, specFirstPatternsGroup, specLastPatternsGroup)\n",
    "    productNames = applyPatternsToPageLocation(productNamePatternsGroup, inputPageLocation, websitesPatternApplicable)\n",
    "    categories   = applyPatternsToPageLocation(mergedCategoryGroup, inputPageLocation, websitesPatternApplicable)\n",
    "    categories   = preprocessCategories(categories, list(productNames))\n",
    "    specs        = applyPatternsToPageLocation(mergedSpecGroup, inputPageLocation, websitesPatternApplicable)\n",
    "    tabularInfo  = applyRelationPatternsToPageLocation(relationsPatternGroup, inputPageLocation, websitesPatternApplicable)\n",
    "    #output = []\n",
    "    #output.extend((\"productName\", productNames))\n",
    "    #output.extend((\"productCategories\", categories))\n",
    "    #output.extend((\"specs\", specs))\n",
    "    output = getHtmlHeader()\n",
    "    sitesCount = str(len(list(websitesPatternApplicable)))\n",
    "    output += getHtmlSection(\"Patterns Belong to Following Websites\", sitesCount, \"site\", websitesPatternApplicable)\n",
    "    productNamesCount  = str(len(list(productNames)))\n",
    "    output += getHtmlSection(\"ProductName\", productNamesCount, \"productName\", productNames)\n",
    "    categoryCount = str(len(list(categories)))\n",
    "    output += getHtmlSection(\"Categories\", categoryCount, \"category\", categories)\n",
    "    specsCount = str(len(list(specs)))\n",
    "    output += getHtmlSection(\"Specs\", specsCount, \"specs\", specs)\n",
    "    tabularSection = getTabularInfo(\"Detailed Description\", str(len(tabularInfo)), \"specTable\", tabularInfo)\n",
    "#     print(\"Tabular section is\")\n",
    "    if len(tabularInfo)>0:\n",
    "        output+=tabularSection\n",
    "    output += getHtmlFooter()\n",
    "    return output\n",
    "\n",
    "#    return json.dumps(output)\n",
    "    #print(\"Product names: \")\n",
    "    #print(productNames)\n",
    "    #print(\"Categories: \")\n",
    "    #print(categories)\n",
    "    #print(\"Specs: \")\n",
    "    #print(specs)\n",
    "def getAllDirectoriesInLocation(loc):\n",
    "    listOfSubDir = [loc+\"/\"+f for f in os.listdir(loc)]\n",
    "    return listOfSubDir\n",
    "\n",
    "def writeOutputToFile(location, data):\n",
    "    text_file = open(location, \"w\")\n",
    "    text_file.write(data)\n",
    "    text_file.close()\n",
    "\n",
    "\n",
    "def doExtractionOnDirectory(directoryLocation, outputFileName):\n",
    "    allDirs = getAllDirectoriesInLocation(directoryLocation)\n",
    "    for d in allDirs:\n",
    "        print(\"Processing \" + d +\"...\")\n",
    "        inputLocation = d+\"/page.html\"\n",
    "        outputLocation = d+\"/output.html\"\n",
    "        data = doExtraction(inputLocation)\n",
    "        writeOutputToFile(outputLocation, data)\n",
    "    print(\"Number of files Processed \" + str(len(allDirs)))\n",
    "#     print(\"all dirs are \")\n",
    "#     print(allDirs)\n",
    "    \n",
    "# doExtraction(\"unseenDocs/page.html\")\n",
    "# if __name__ == \"__main__\":\n",
    "#     print doExtraction(sys.argv[1])\n",
    "\n",
    "doExtractionOnDirectory(\"testingData\", \"output.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
