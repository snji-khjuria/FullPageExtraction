{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the corpus directory out of which we'll learn patterns: \n",
      "Corpus directory is productNameData/amazon/corpus\n",
      "Train Files are ['productNameData/amazon/corpus/page1', 'productNameData/amazon/corpus/page6', 'productNameData/amazon/corpus/page7', 'productNameData/amazon/corpus/page5', 'productNameData/amazon/corpus/page8', 'productNameData/amazon/corpus/page3']\n",
      "Test files are ['productNameData/amazon/corpus/page9', 'productNameData/amazon/corpus/page10', 'productNameData/amazon/corpus/page2', 'productNameData/amazon/corpus/page4']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "#corpus directory for flipkart\n",
    "# productNameData/flipkart/corpus\n",
    "print(\"Enter the corpus directory out of which we'll learn patterns: \")\n",
    "# corpusDirectory = raw_input()\n",
    "corpusDirectory = \"productNameData/amazon/corpus\"\n",
    "print(\"Corpus directory is \" + corpusDirectory)\n",
    "directories = getAllDirectoriesInLocation(corpusDirectory)\n",
    "(trainDirs, testDirs) = trainTestSplit(directories)\n",
    "print(\"Train Files are \" + str(trainDirs))\n",
    "print(\"Test files are \" + str(testDirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "#do train/test split\n",
    "def trainTestSplit(files):\n",
    "    sixtyPercent = int(len(files)*(0.6))\n",
    "    if sixtyPercent<4:\n",
    "        print(\"We won't be able to report accuracy of patterns\")\n",
    "        return (files, [])\n",
    "    else:\n",
    "        return (files[:sixtyPercent], files[sixtyPercent:])\n",
    "\n",
    "def getAllDirectoriesInLocation(loc):\n",
    "    listOfSubDir = [loc+\"/\"+f for f in os.listdir(loc)]\n",
    "    return listOfSubDir\n",
    "\n",
    "\n",
    "def removeMultipleWhiteSpaces(s):\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "\n",
    "def getProductNameSeed(fileLocation):\n",
    "    with open(fileLocation) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content] \n",
    "    return removeMultipleWhiteSpaces(content[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getPageLocationAndSeed(d):\n",
    "    output = []\n",
    "    for pageDir in d:\n",
    "        pageLocation = pageDir + \"/page.html\"\n",
    "        seedLocation = pageDir + \"/seed\"\n",
    "        seed = getProductNameSeed(seedLocation)\n",
    "        output.append((pageLocation, seed))\n",
    "    return output\n",
    "\n",
    "\n",
    "#read the page from pageLocation\n",
    "def readPage(pageLocation):\n",
    "    htmlPageContent = \"\"\n",
    "    with open(pageLocation, 'r') as myfile:\n",
    "        htmlPageContent = myfile.read().strip()\n",
    "    return htmlPageContent\n",
    "\n",
    "def removeTerminatedAnd(s):\n",
    "    return re.sub(\"&amp;\", \"&\", s)\n",
    "\n",
    "\n",
    "\n",
    "#document processing logic at this stage is about removing multiple whitespaces into single one \n",
    "def preprocessDocument(document):\n",
    "    return removeTerminatedAnd(' '.join(document.split()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getLeftAndRightContexts(pageContent, seed):\n",
    "    b = getEachSeedLocationsInPage(pageContent, seed)\n",
    "    output = []\n",
    "    totalLength = len(pageContent)\n",
    "    leftContexts = []\n",
    "    rightContexts = []\n",
    "    for (s, e) in b:\n",
    "        leftContext = pageContent[max(0, s-100):s]\n",
    "        leftContext = leftContext[::-1]\n",
    "        rightContext = pageContent[e:min(totalLength, e+100)]\n",
    "        leftContexts.append(leftContext)\n",
    "        rightContexts.append(rightContext)\n",
    "    return (leftContexts, rightContexts)\n",
    "    \n",
    "    \n",
    "#find all start, end pairs of particular key\n",
    "def getAllStartEndPairs(document, key):\n",
    "    keyLength = len(key)\n",
    "    return [(i, i+keyLength) for i in range(len(document)) if document.startswith(key, i)]\n",
    " \n",
    "    \n",
    "#find seeds for one particular seed(at this stage call only getAllStartEndPairs())\n",
    "def getEachSeedLocationsInPage(htmlPageContent, seed):\n",
    "    return getAllStartEndPairs(htmlPageContent, seed)\n",
    "\n",
    "def printContextInformation(contexts, pageAndSeed, rev=False):\n",
    "    \n",
    "    for index in range(0, len(pageAndSeed)):\n",
    "        (pageLocation, seed) = pageAndSeed[index]\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        contextPerPage = contexts[index]\n",
    "        print(\"For seed \" + str(seed))\n",
    "        print(\"Context is following: \" + pageLocation )#+ \" number \" + str(contextPerPage))\n",
    "        for item in contextPerPage:\n",
    "            if rev==True:\n",
    "                item = item[::-1]\n",
    "            print(item)\n",
    "            print(\"---------------------\")\n",
    "\n",
    "def getCommonPrefix(s1, s2):\n",
    "    l = [s1, s2]\n",
    "    return os.path.commonprefix(l)\n",
    "\n",
    "\n",
    "\n",
    "def insertCommonPrefix(results, commonPrefix):\n",
    "    if commonPrefix in results or len(commonPrefix)<=0:\n",
    "        return results\n",
    "    r = list(results)\n",
    "    for item in r:\n",
    "        if len(item)<len(commonPrefix) and commonPrefix.startswith(item):\n",
    "            results.remove(item)\n",
    "    r=list(results)\n",
    "    for item in r:\n",
    "        if len(item)>len(commonPrefix) and item.startswith(commonPrefix):\n",
    "            return results\n",
    "    results.add(commonPrefix)\n",
    "    return results\n",
    "\n",
    "def doPrefixIntersection(list1, list2):\n",
    "    results = set()\n",
    "    for item1 in list1:\n",
    "        commonPrefix = \"\"\n",
    "        for item2 in list2:\n",
    "            c = getCommonPrefix(item1, item2)\n",
    "            if len(c)>len(commonPrefix):\n",
    "                commonPrefix = c\n",
    "        results = insertCommonPrefix(results, commonPrefix)\n",
    "    return results\n",
    "\n",
    "\n",
    "def doIntersection(patterns):\n",
    "    if len(patterns)<=0:\n",
    "        return patterns\n",
    "    result = patterns[0]\n",
    "    for index in range(1, len(patterns)):\n",
    "        result = doPrefixIntersection(result, patterns[index])\n",
    "    return result\n",
    "\n",
    "\n",
    "def getLeftPatterns(leftContexts):\n",
    "    lp = doIntersection(leftContexts)\n",
    "    results = []\n",
    "    for item in lp:\n",
    "        results.append(item[::-1])\n",
    "    return results\n",
    "\n",
    "\n",
    "def getRightPatterns(rightContexts):\n",
    "    return list(doIntersection(rightContexts))\n",
    "\n",
    "\n",
    "def allPossiblePairs(leftPatterns, rightPatterns):\n",
    "    patterns = []\n",
    "    for lp in leftPatterns:\n",
    "        for rp in rightPatterns:\n",
    "            patterns.append((lp, rp))\n",
    "    return patterns\n",
    "\n",
    "#Pattern is (l, r) and match them to htmlPageContent\n",
    "def findEntitySetwrtPattern(htmlPageContent, (l, r)):\n",
    "    #for each start location of pattern find its end\n",
    "    #for each end page find the pattern right\n",
    "    #extract everything till that point\n",
    "    #after extraction move one point above that pattern string\n",
    "    results = []\n",
    "    for m in re.finditer(re.escape(l), htmlPageContent):\n",
    "        start = m.start()\n",
    "        end = m.end()\n",
    "        rightPage = htmlPageContent[end:]\n",
    "        rightLoc  = rightPage.find(r)\n",
    "        if rightLoc==-1:\n",
    "            break\n",
    "        element = rightPage[:rightLoc]\n",
    "        if len(element)>1 and len(element)<300:\n",
    "            results.append(element)\n",
    "    return set(results)\n",
    "\n",
    "\n",
    "def extractSet(patterns, htmlPageContent):\n",
    "    output = []\n",
    "    for pattern in patterns:\n",
    "        output.extend(findEntitySetwrtPattern(htmlPageContent, pattern))\n",
    "    return set(output)\n",
    "\n",
    "\n",
    "#remove elements which were actually tag\n",
    "def isTag(s):\n",
    "    if s.find(\"<\")!=-1 and s.find(\">\")!=-1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#preprocess results before writing it to file\n",
    "def preprocessResults(output):\n",
    "    result = []\n",
    "    for o in output:\n",
    "        if isTag(o):\n",
    "            continue\n",
    "        result.append(o)\n",
    "    return result\n",
    "\n",
    "def filterPatterns(pageLocationAndSeeds, patterns, applyClass=False, regExpIn=\"\", regExpOut=\"\"):\n",
    "    seedsSet = set()\n",
    "    for (pageLoc, s) in pageLocationAndSeeds:\n",
    "        seedsSet.add(s)\n",
    "    seeds = list(seedsSet)\n",
    "    patternSuccess = []\n",
    "    for index in range(0, len(patterns)):\n",
    "        patternSuccess.append(0)\n",
    "    for index in range(0, len(patterns)):\n",
    "        for (pageLocation, seed) in pageLocationAndSeeds:\n",
    "            pageContent = preprocessDocument(readPage(pageLocation))\n",
    "            if applyClass == True:\n",
    "                pageContent = doProcessingWithoutClass(pageLocation, regExpIn, regExpOut)\n",
    "            resultsFound = extractSet([patterns[index]], pageContent)\n",
    "            if seed in resultsFound:\n",
    "                patternSuccess[index]+=1\n",
    "                \n",
    "    output = []\n",
    "    for index in range(0, len(patterns)):\n",
    "        if patternSuccess[index]>0:\n",
    "            output.append(patterns[index])\n",
    "    return output\n",
    "\n",
    "\n",
    "# def filterPatterns(pageLocationAndSeeds, patterns, applyClass=False, regExpIn=\"\", regExpOut=\"\"):\n",
    "#     seedsSet = set()\n",
    "#     for (pageLoc, seed) in pageLocationAndSeeds:\n",
    "#         for s in seed:\n",
    "#             seedsSet.add(s)\n",
    "#     seeds = list(seedsSet)\n",
    "#     patternSuccess = []\n",
    "#     for index in range(0, len(patterns)):\n",
    "#         patternSuccess.append(0)\n",
    "#     for index in range(0, len(patterns)):\n",
    "#         for (pageLocation, seed) in pageLocationAndSeeds:\n",
    "#             pageContent = preprocessDocument(readPage(pageLocation))\n",
    "#             if applyClass == True:\n",
    "#                 pageContent = doProcessingWithoutClass(preprocessDocument(readPage(pageLocation)), regExpIn, regExpOut)\n",
    "#             resultsFound = extractSet([patterns[index]], pageContent)\n",
    "#             flag = True\n",
    "#             for s in seed:\n",
    "#                 if not s in resultsFound:\n",
    "#                     flag=False\n",
    "#             if flag==True:\n",
    "#                 patternSuccess[index]+=1\n",
    "                \n",
    "#     output = []\n",
    "#     for index in range(0, len(patterns)):\n",
    "#         if patternSuccess[index]>0:\n",
    "#             output.append(patterns[index])\n",
    "#     return output\n",
    "\n",
    "\n",
    "def doProcessingWithoutClass(s, regExpIn, regExpOut):\n",
    "    allManaged =  re.sub(regExpIn, regExpOut, s)\n",
    "    removeQuoteIn = r'\"[^\"]*\"'\n",
    "    removeQuoteOut = r'\"\"'\n",
    "    return re.sub(removeQuoteIn, removeQuoteOut, allManaged)\n",
    "#     i = \"class[\\s]*=[\\s]*\"\n",
    "#     o       = \"class=\"\n",
    "#     s = re.sub(i, o, s)\n",
    "#     i = \"([^class])=\\\"[^\\\"]*\\\"\"\n",
    "#     o = \"\\\\1=\\\"\\\"\"\n",
    "#     return re.sub(i, o, s)\n",
    "\n",
    "\n",
    "\n",
    "def getLastWordWithoutEqualSign(leftContext):\n",
    "    words = leftContext.strip().split(\" \")\n",
    "    totalWords = len(words)\n",
    "    if len(words)<2:\n",
    "        return \"\"\n",
    "    else:\n",
    "        if words[totalWords-1]==\"=\":\n",
    "            return words[totalWords-2]\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "def getSpecialWords(document, seedsSet):\n",
    "    totalLength = len(document)\n",
    "    specialWords = []\n",
    "    for s in seedsSet:\n",
    "        allSeedPositions = getAllStartEndPairs(document, s)\n",
    "        for (start, end) in allSeedPositions:\n",
    "            prevLoc = start-1\n",
    "            nextLoc = end\n",
    "            if prevLoc>=0 and nextLoc<totalLength:\n",
    "                prevQuot = document[prevLoc]\n",
    "                nextQuot  = document[nextLoc]\n",
    "#                 print(prevQuot + \" \" + nextQuot)\n",
    "                if prevQuot==\"\\\"\" and nextQuot==\"\\\"\":\n",
    "                    leftContext = document[max(0, prevLoc-100):prevLoc]\n",
    "                    lastWord = getLastWordWithoutEqualSign(leftContext)\n",
    "                    if len(lastWord)>0:\n",
    "                        specialWords.append(lastWord)\n",
    "    return specialWords\n",
    "\n",
    "\n",
    "\n",
    "def createRegExpFromWordStr(wordsStr):\n",
    "#     wordsStr = getWordsStr(words)\n",
    "#     print(\"wordsstr is \" + wordsStr)\n",
    "    return (\"(\" + wordsStr +\")[\\s]*=[\\s]*\\\"([^\\\"]*)\\\"\", \"\\\\1=\\\\2\")\n",
    "\n",
    "\n",
    "\n",
    "def getWordsStr(words):\n",
    "    out = words[0]\n",
    "    if len(words)==1:\n",
    "        return out\n",
    "    else:\n",
    "        for index in range(1, len(words)):\n",
    "            out+=\"|\"+words[index]\n",
    "    print(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def getAllSpecialWordsAsString(pageLocationAndSeed):\n",
    "    specialWords = []\n",
    "    specialWords.append(\"class\")\n",
    "    for (pageLocation, seeds) in pageLocationAndSeed:\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        specialWords.extend(getSpecialWords(pageContent, seeds))\n",
    "    specialWords = list(set(specialWords))\n",
    "    return getWordsStr(specialWords)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getAllPatternsByPlainStringMatch(corpusLocation):\n",
    "    directories             = getAllDirectoriesInLocation(corpusLocation)\n",
    "    (trainDirs, testDirs)   = trainTestSplit(directories)\n",
    "    pageLocationsAndSeed    = getPageLocationAndSeed(trainDirs)\n",
    "    testPageLocationAndSeed = getPageLocationAndSeed(testDirs)\n",
    "    leftContexts  = []\n",
    "    rightContexts = []\n",
    "    for (pageLocation, seed) in pageLocationsAndSeed:\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        (leftContextsPerPage, rightContextsPerPage) = getLeftAndRightContexts(pageContent, seed)\n",
    "        leftContexts.append(leftContextsPerPage)\n",
    "        rightContexts.append(rightContextsPerPage)\n",
    "#     printContextInformation(leftContexts, pageLocationsAndSeed, True)\n",
    "#     printContextInformation(rightContexts, pageLocationsAndSeed)\n",
    "    leftPatterns = getLeftPatterns(leftContexts)\n",
    "    rightPatterns = getRightPatterns(rightContexts)\n",
    "    \n",
    "#     print(\"Left patterns are \" + str(leftPatterns))\n",
    "#     print(\"Right patterns are \" + str(rightPatterns))\n",
    "    patterns = allPossiblePairs(leftPatterns, rightPatterns)\n",
    "#     print(\"All possible patterns: \")\n",
    "#     print(patterns)\n",
    "    patterns = filterPatterns(pageLocationsAndSeed, patterns)\n",
    "    #TODO if number of patterns are empty go for empty class thing\n",
    "#     print(\"Final Patterns \")\n",
    "#     print(patterns)\n",
    "    recall = 0\n",
    "    extraResults = 0\n",
    "    for (pageLocation, seed) in testPageLocationAndSeed:\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        resultsPerPage = preprocessResults(list(extractSet(patterns, pageContent)))\n",
    "#         resultsPerPage = list(set(resultsPerPage))\n",
    "        if seed in resultsPerPage:\n",
    "            recall += 1\n",
    "        if len(resultsPerPage)>1:\n",
    "            extraResults += len(resultsPerPage)-1\n",
    "#         print(\"Results per page \" + str(resultsPerPage))\n",
    "    seedsMissed = len(testPageLocationAndSeed)-recall\n",
    "#     print(\"Seeds missed: \" + str(seedsMissed))\n",
    "#     print(\"Extra junk: \"+ str(extraResults))\n",
    "    return (patterns, seedsMissed, extraResults, len(testDirs))\n",
    "    \n",
    "# getAllPatternsByPlainStringMatch(corpusDirectory)\n",
    "\n",
    "def getAllPatternsByRetainingOnlyClassValue(corpusLocation):\n",
    "    directories             = getAllDirectoriesInLocation(corpusLocation)\n",
    "    (trainDirs, testDirs)   = trainTestSplit(directories)\n",
    "    pageLocationsAndSeed    = getPageLocationAndSeed(trainDirs)\n",
    "    testPageLocationAndSeed = getPageLocationAndSeed(testDirs)\n",
    "    specialWordsString      = getAllSpecialWordsAsString(pageLocationsAndSeed)\n",
    "    (regExpIn, regExpOut)   = createRegExpFromWordStr(specialWordsString)\n",
    "#     print(\"Regular expression is \")\n",
    "#     print(regExpIn)\n",
    "    leftContexts  = []\n",
    "    rightContexts = []\n",
    "    for (pageLocation, seed) in pageLocationsAndSeed:\n",
    "        pageContent = doProcessingWithoutClass(preprocessDocument(readPage(pageLocation)), regExpIn, regExpOut)\n",
    "        (leftContextsPerPage, rightContextsPerPage) = getLeftAndRightContexts(pageContent, seed)\n",
    "        leftContexts.append(leftContextsPerPage)\n",
    "        rightContexts.append(rightContextsPerPage)\n",
    "#     printContextInformation(leftContexts, pageLocationsAndSeed, True)\n",
    "#     printContextInformation(rightContexts, pageLocationsAndSeed)\n",
    "#     print(\"Printed context infromation\")\n",
    "    leftPatterns = getLeftPatterns(leftContexts)\n",
    "    rightPatterns = getRightPatterns(rightContexts)\n",
    "    \n",
    "#     print(\"Left patterns are \" + str(leftPatterns))\n",
    "#     print(\"Right patterns are \" + str(rightPatterns))\n",
    "    patterns = allPossiblePairs(leftPatterns, rightPatterns)\n",
    "#     print(\"All possible patterns: \")\n",
    "#     print(patterns)\n",
    "#     patterns = filterPatterns(pageLocationsAndSeed, patterns, True, regExpIn, regExpOut)\n",
    "    #TODO if number of patterns are empty go for empty class thing\n",
    "#     print(\"Final Patterns \")\n",
    "#     print(patterns)\n",
    "    recall = 0\n",
    "    extraResults = 0\n",
    "    for (pageLocation, seed) in testPageLocationAndSeed:\n",
    "        pageContent = doProcessingWithoutClass(preprocessDocument(readPage(pageLocation)), regExpIn, regExpOut)\n",
    "        resultsPerPage = preprocessResults(list(extractSet(patterns, pageContent)))\n",
    "        if seed in resultsPerPage:\n",
    "            recall += 1\n",
    "#         else:\n",
    "#             print(\"Page location: \" + pageLocation)\n",
    "#             print(\"Seed is \" + seed)\n",
    "#             print(resultsPerPage)\n",
    "        if len(resultsPerPage)>1:\n",
    "            extraResults += len(resultsPerPage)-1\n",
    "#     print(\"number of pages\" + str(len(testPageLocationAndSeed)))\n",
    "    seedsMissed = len(testPageLocationAndSeed)-recall\n",
    "#     print(\"Seeds missed: \" + str(seedsMissed))\n",
    "#     print(\"Extra junk: \"+ str(extraResults))\n",
    "    return (patterns, seedsMissed, extraResults, len(testDirs), specialWordsString)\n",
    "    \n",
    "# getAllPatternsByRetainingOnlyClassValue(corpusDirectory)\n",
    "\n",
    "def writeListToFile(loc, l):\n",
    "    with open(loc, 'w') as f:\n",
    "        for item in l:\n",
    "            f.write(item+\"\\n\")\n",
    "\n",
    "            \n",
    "def escapeAllDoubleQuote(s):\n",
    "    return re.sub(\"\\\"\", \"\\\\\\\"\", s)\n",
    "            \n",
    "def writeProductPatternsToFile(fileLocation, productPatterns):\n",
    "    header = \"GroupId\\tWebsiteName\\tPatternType\\tMissed\\tJunk\\tOutof\\tLeftPattern\\tRightPattern\"\n",
    "    groupId = 1\n",
    "    output = []\n",
    "    output.append(header)\n",
    "    for (website, pType, patterns, missed, junk, total) in productPatterns:\n",
    "        rowPrefix = str(groupId) + \"\\t\" + website + \"\\t\" + pType\n",
    "        rowPrefix+=\"\\t\" + str(missed) + \"\\t\" + str(junk) + \"\\t\" + str(total)\n",
    "        for (l, r) in patterns:\n",
    "            row = rowPrefix + \"\\t\" + l + \"\\t\" + r\n",
    "            output.append(row)\n",
    "        groupId+=1\n",
    "#     print(\"output is \")\n",
    "#     for item in output:\n",
    "#         print(item)\n",
    "    writeListToFile(fileLocation, output)\n",
    "    print(\"Output written at location: \" + fileLocation)\n",
    "    \n",
    "    \n",
    "def getPatternStore(eCommerceDataSetLocation):\n",
    "    allWebsites = getAllDirectoriesInLocation(eCommerceDataSetLocation)\n",
    "#     print(\"All websites are \" + str(allWebsites))\n",
    "    patternsStore = []\n",
    "    for website in allWebsites:\n",
    "        corpusLocation = website + \"/corpus\"\n",
    "        websiteName = os.path.basename(website)\n",
    "        (plainPatterns, plainMissed, plainJunkCount, plainTotal) = getAllPatternsByPlainStringMatch(corpusLocation)\n",
    "        (noValPatterns, noValMissed, noValJunkCount, noValTotal, words) = getAllPatternsByRetainingOnlyClassValue(corpusLocation)\n",
    "        print(websiteName)\n",
    "        print(plainMissed)\n",
    "        print(noValMissed)\n",
    "        if plainMissed <= noValMissed:\n",
    "            patterns = (websiteName, \"plainPattern\", plainPatterns, plainMissed, plainJunkCount, plainTotal)\n",
    "            print(plainPatterns)\n",
    "        else:\n",
    "            patterns = (websiteName, \"noValuePattern_\"+words, noValPatterns, noValMissed, noValJunkCount, noValTotal)\n",
    "        patternsStore.append(patterns)\n",
    "    for p in patternsStore:\n",
    "        print(p)\n",
    "    return patternsStore\n",
    "\n",
    "\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter e-commerce data location: \n",
      "productNameData\n",
      "Enter outputLocation\n",
      "newPatternsLearnt\n",
      "Patterns will be found at newPatternsLearnt/ProductPatterns.tsv\n",
      "flipkart\n",
      "0\n",
      "0\n",
      "[('\">', '</div><svg width=\"16\" height=\"27\" viewBox=\"0 0 16 27\" xmlns=\"http://www.w3.org/2000/svg\" class=\"_2XP')]\n",
      "pubId|class|minValue\n",
      "snapdeal\n",
      "0\n",
      "0\n",
      "[('tyle: outside none none; position: absolute; width: 553px; z-index: 0; display: none;\"> <img title=\"', '\" slidenum=\"1\" class=\"cloudzoom\" bigsrc=\"https://n'), ('tyle: outside none none; position: absolute; width: 553px; z-index: 0; display: none;\"> <img title=\"', '\" slidenum=\"2\" class=\"cloudzoom\" bigsrc=\"https://n'), ('\" class=\"tileImg lazy-load\" title=\"', '\" alt=\"'), ('emap\\', \\'k4\\': \\'See All Categories\\'}, ]\" type=\"hidden\"> </ul> </div> </div></div> </div><input value=\"', '\" id=\"productNamePDP\" type=\"hidden\"> <input id=\"superCategoryLabel\" name=\"superCategoryLabel\" value='), ('nk itemprop=\"availability\" href=\"http://schema.org/InStock\"> <div itemprop=\"name\" class=\"disp-none\">', '</div> <div id=\"buyPriceBox\" class=\"elecPriceTile buyNowBlock row\"> <div class=\"col-xs-21 reset-padd'), ('em\"> <meta property=\"og:description\" content=\"\"> <meta name=\"og_title\" property=\"og:title\" content=\"', '\"> <meta name=\"og_site_name\" property=\"og:site_name\" content=\"Snapdeal.com\"> <meta name=\"og_image\" p'), ('none; position: absolute; width: 553px; z-index: 50; display: block;\"> <img itemprop=\"image\" title=\"', '\" slidenum=\"0\" class=\"cloudzoom\" bigsrc=\"https://n'), ('/amp\"> <meta name=\"description\" content=\"Buy ', ' Online '), ('\"> </div> <div class=\"tile-desc\"> <p class=\"product-title\">', '</p> <p class=\"product-offer-price\"> Rs. '), ('\" alt=\"', '\"> </div> <div class=\"tile-desc\"> <p class=\"product-title\">'), ('\" alt=\"', '\" src=\"page'), ('; list-style: outside none none; position: relative; width: 73px; margin-bottom: 8px;\"> <img title=\"', '\" alt=\"'), ('\" class=\"pdp-e-i-head\"> ', '</h1> </div> <div class=\"col-xs-2\"> <div class=\"shortlist-icon-wrpr comp-animated-icon \"> <span clas'), ('\", \"productNamePDP\": \"', '\", \"hardBundlingCss\": \"https://i1.sdlcdn.com/css/amex1507014675285/snap/components/bundling/hardBund'), (' Snapdeal \"> <meta name=\"twitter:description\" content=\"Buy ', ' Online '), ('-elec-topcenter-inner layout\"> <div class=\"row\"> <div class=\"col-xs-22\"> <h1 itemprop=\"name\" title=\"', '\" class=\"pdp-e-i-head\"> ')]\n",
      "amazon\n",
      "0\n",
      "1\n",
      "[('class=\"sims-fbt-checkbox-label\"><span class=\"sims-fbt-this-item a-text-bold\">This item:</span><span>', '</span> <span class=\"a-color-price\"><span class=\"p13n-sc-price\"><span style=\"text-decoration: inheri'), ('> <h1 id=\"title\" class=\"a-size-large a-spacing-none\"> <span id=\"productTitle\" class=\"a-size-large\"> ', ' </span> <span id=\"titleEDPPlaceHolder\"></span> </h1> <div id=\"expandTitleToggle\" class=\"a-section a'), (' class=\"a-align-center sims-fbt-image-1\"><span class=\"a-list-item\"><div class=\"a-section\"><img alt=\"', '\" src=\"page_files/')]\n",
      "('flipkart', 'plainPattern', [('\">', '</div><svg width=\"16\" height=\"27\" viewBox=\"0 0 16 27\" xmlns=\"http://www.w3.org/2000/svg\" class=\"_2XP')], 0, 0, 4)\n",
      "('snapdeal', 'plainPattern', [('tyle: outside none none; position: absolute; width: 553px; z-index: 0; display: none;\"> <img title=\"', '\" slidenum=\"1\" class=\"cloudzoom\" bigsrc=\"https://n'), ('tyle: outside none none; position: absolute; width: 553px; z-index: 0; display: none;\"> <img title=\"', '\" slidenum=\"2\" class=\"cloudzoom\" bigsrc=\"https://n'), ('\" class=\"tileImg lazy-load\" title=\"', '\" alt=\"'), ('emap\\', \\'k4\\': \\'See All Categories\\'}, ]\" type=\"hidden\"> </ul> </div> </div></div> </div><input value=\"', '\" id=\"productNamePDP\" type=\"hidden\"> <input id=\"superCategoryLabel\" name=\"superCategoryLabel\" value='), ('nk itemprop=\"availability\" href=\"http://schema.org/InStock\"> <div itemprop=\"name\" class=\"disp-none\">', '</div> <div id=\"buyPriceBox\" class=\"elecPriceTile buyNowBlock row\"> <div class=\"col-xs-21 reset-padd'), ('em\"> <meta property=\"og:description\" content=\"\"> <meta name=\"og_title\" property=\"og:title\" content=\"', '\"> <meta name=\"og_site_name\" property=\"og:site_name\" content=\"Snapdeal.com\"> <meta name=\"og_image\" p'), ('none; position: absolute; width: 553px; z-index: 50; display: block;\"> <img itemprop=\"image\" title=\"', '\" slidenum=\"0\" class=\"cloudzoom\" bigsrc=\"https://n'), ('/amp\"> <meta name=\"description\" content=\"Buy ', ' Online '), ('\"> </div> <div class=\"tile-desc\"> <p class=\"product-title\">', '</p> <p class=\"product-offer-price\"> Rs. '), ('\" alt=\"', '\"> </div> <div class=\"tile-desc\"> <p class=\"product-title\">'), ('\" alt=\"', '\" src=\"page'), ('; list-style: outside none none; position: relative; width: 73px; margin-bottom: 8px;\"> <img title=\"', '\" alt=\"'), ('\" class=\"pdp-e-i-head\"> ', '</h1> </div> <div class=\"col-xs-2\"> <div class=\"shortlist-icon-wrpr comp-animated-icon \"> <span clas'), ('\", \"productNamePDP\": \"', '\", \"hardBundlingCss\": \"https://i1.sdlcdn.com/css/amex1507014675285/snap/components/bundling/hardBund'), (' Snapdeal \"> <meta name=\"twitter:description\" content=\"Buy ', ' Online '), ('-elec-topcenter-inner layout\"> <div class=\"row\"> <div class=\"col-xs-22\"> <h1 itemprop=\"name\" title=\"', '\" class=\"pdp-e-i-head\"> ')], 0, 0, 4)\n",
      "('amazon', 'plainPattern', [('class=\"sims-fbt-checkbox-label\"><span class=\"sims-fbt-this-item a-text-bold\">This item:</span><span>', '</span> <span class=\"a-color-price\"><span class=\"p13n-sc-price\"><span style=\"text-decoration: inheri'), ('> <h1 id=\"title\" class=\"a-size-large a-spacing-none\"> <span id=\"productTitle\" class=\"a-size-large\"> ', ' </span> <span id=\"titleEDPPlaceHolder\"></span> </h1> <div id=\"expandTitleToggle\" class=\"a-section a'), (' class=\"a-align-center sims-fbt-image-1\"><span class=\"a-list-item\"><div class=\"a-section\"><img alt=\"', '\" src=\"page_files/')], 0, 0, 4)\n",
      "Output written at location: newPatternsLearnt/ProductPatterns.tsv\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter e-commerce data location: \")\n",
    "eCommerceDataLocation = raw_input()\n",
    "print(\"Enter outputLocation\")\n",
    "outputLocation = raw_input()\n",
    "outputLocation+=\"/ProductPatterns.tsv\"\n",
    "print(\"Patterns will be found at \" + str(outputLocation))\n",
    "patternsStore = getPatternStore(eCommerceDataLocation)\n",
    "writeProductPatternsToFile(outputLocation, patternsStore)\n",
    "#productNameData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('productNameData/flipkart/corpus/page1/page.html', 'Mi A1 (Black, 64 GB) (4 GB RAM)'), ('productNameData/flipkart/corpus/page6/page.html', 'Apple iPhone SE (Space Grey, 32 GB)'), ('productNameData/flipkart/corpus/page7/page.html', 'Samsung Galaxy On5 (Gold, 8 GB) (1.5 GB RAM)'), ('productNameData/flipkart/corpus/page5/page.html', 'Puma Men Puma Black-High Risk Red Sports Sandals')]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testPageLocatioWithSeed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-01aa41b11c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageLocationsWithSeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtestPageLocationWithSeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPageLocationAndSeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestPageLocatioWithSeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testPageLocatioWithSeed' is not defined"
     ]
    }
   ],
   "source": [
    "pageLocationsWithSeed = getPageLocationAndSeed(trainDirs)\n",
    "print(pageLocationsWithSeed)\n",
    "testPageLocationWithSeed = getPageLocationAndSeed(testDirs)\n",
    "print(testPageLocationWithSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All websites are ['productNameData/flipkart', 'productNameData/.~lock.ProductPatterns.tsv#', 'productNameData/ProductPatterns.tsv', 'productNameData/amazon']\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 20] Not a directory: 'productNameData/.~lock.ProductPatterns.tsv#/corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-1ea0fc0515ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcorpusLocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebsite\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/corpus\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mwebsiteName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwebsite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mplainPatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplainMissed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplainJunkCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplainTotal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAllPatternsByPlainStringMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mnoValPatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoValMissed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoValJunkCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoValTotal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAllPatternsByRetainingOnlyClassValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     print(\"Patterns are \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-feb0327ec15d>\u001b[0m in \u001b[0;36mgetAllPatternsByPlainStringMatch\u001b[0;34m(corpusLocation)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetAllPatternsByPlainStringMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdirectories\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0mgetAllDirectoriesInLocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mtrainDirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestDirs\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtrainTestSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpageLocationsAndSeed\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mgetPageLocationAndSeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtestPageLocationAndSeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPageLocationAndSeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-15023fe74e07>\u001b[0m in \u001b[0;36mgetAllDirectoriesInLocation\u001b[0;34m(loc)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetAllDirectoriesInLocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlistOfSubDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlistOfSubDir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 20] Not a directory: 'productNameData/.~lock.ProductPatterns.tsv#/corpus'"
     ]
    }
   ],
   "source": [
    "eCommerceDataSetLocation = \"productNameData\"\n",
    "allWebsites = getAllDirectoriesInLocation(eCommerceDataSetLocation)\n",
    "print(\"All websites are \" + str(allWebsites))\n",
    "patternsStore = []\n",
    "for website in allWebsites:\n",
    "    corpusLocation = website + \"/corpus\"\n",
    "    websiteName = os.path.basename(website)\n",
    "    (plainPatterns, plainMissed, plainJunkCount, plainTotal) = getAllPatternsByPlainStringMatch(corpusLocation)\n",
    "    (noValPatterns, noValMissed, noValJunkCount, noValTotal) = getAllPatternsByRetainingOnlyClassValue(corpusLocation)\n",
    "#     print(\"Patterns are \")\n",
    "#     print(plainPatterns)\n",
    "    if plainMissed < noValMissed:\n",
    "#         print(\"yes it is\")\n",
    "        patterns = (websiteName, \"plainPattern\", plainPatterns, plainMissed, plainJunkCount, plainTotal)\n",
    "    else:\n",
    "        patterns = (websiteName, \"noValuePattern\", noValPatterns, noValMissed, noValJunkCount, noValTotal)\n",
    "    patternsStore.append(patterns)\n",
    "print(\"Pattern store is \" + str(patternsStore))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sanjeev&kumar'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeTerminatedAnd(s):\n",
    "    return re.sub(\"&amp;\", \"&\", s)\n",
    "removeTerminatedAnd(\"sanjeev&amp;kumar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sanju $ kumar'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"sanjeev\", \"$\", \"sanju sanjeev kumar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
