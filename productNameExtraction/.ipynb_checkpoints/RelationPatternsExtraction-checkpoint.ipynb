{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getEachSeedLocationsInPage(document, (lSeed, rSeed), kvDiff=200):\n",
    "    lSeedLocations = [(i, i+len(lSeed)) for i in range(len(document)) if document.startswith(lSeed, i)]\n",
    "    docLength = len(document)\n",
    "    output = []\n",
    "    for (ls, le) in lSeedLocations:\n",
    "        subStr = document[le: min(le+200, docLength)]\n",
    "        loc = subStr.find(rSeed)\n",
    "        if loc==-1:\n",
    "            continue\n",
    "        rs = loc\n",
    "        re = loc + len(rSeed)\n",
    "        output.append((ls, le, rs, re))\n",
    "    return output\n",
    "    \n",
    "\n",
    "def getSeedsPositions(pageContent, presentSeeds):\n",
    "    output = []\n",
    "    for seed in presentSeeds:\n",
    "        output.append(getEachSeedLocationsInPage(pageContent, seed))\n",
    "    return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 're' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-789b51d7571f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseedsMissed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextraResults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m \u001b[0mgetAllPatternsByPlainStringMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tablesData/flipkart/corpus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-190-789b51d7571f>\u001b[0m in \u001b[0;36mgetAllPatternsByPlainStringMatch\u001b[0;34m(corpusLocation)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpageLocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpageLocationsAndSeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mpageContent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mlcPerPage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbcPerPage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcPerPage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetContextsForAllSeeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageContent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;31m#         (leftContextsPerPage, rightContextsPerPage) = getContextsForAllSeeds(pageContent, seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mleftContexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcPerPage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-190-789b51d7571f>\u001b[0m in \u001b[0;36mgetContextsForAllSeeds\u001b[0;34m(pageContent, seed)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mlcPerS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbcPerS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcPerS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLeftBetweenRightContexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageContent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;31m#         if len(lcPerS)==0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m#             print(\"Zero\\n\\n\\n\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-190-789b51d7571f>\u001b[0m in \u001b[0;36mgetLeftBetweenRightContexts\u001b[0;34m(pageContent, seed)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetLeftBetweenRightContexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageContent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetEachSeedLocationsInPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageContent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mleftContexts\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mgetLeftContexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpageContent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-190-789b51d7571f>\u001b[0m in \u001b[0;36mgetEachSeedLocationsInPage\u001b[0;34m(document, (lSeed, rSeed), kvDiff)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrSeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubStr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 're' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def getAllDirectoriesInLocation(loc):\n",
    "    listOfSubDir = [loc+\"/\"+f for f in os.listdir(loc)]\n",
    "    return listOfSubDir\n",
    "\n",
    "#do train/test split\n",
    "def trainTestSplit(files):\n",
    "    sixtyPercent = int(len(files)*(0.6))\n",
    "    if sixtyPercent<4:\n",
    "        print(\"We won't be able to report accuracy of patterns\")\n",
    "        return (files, [])\n",
    "    else:\n",
    "        return (files[:sixtyPercent], files[sixtyPercent:])\n",
    "\n",
    "#read all realtion sseds    \n",
    "def readAllRelationSeeds(seedsLocation):\n",
    "    relationSeeds = []\n",
    "    with open(seedsLocation) as f:\n",
    "        for line in f:\n",
    "            relationSeed = re.split(r'\\t+', line)\n",
    "            if len(relationSeed)!=2:\n",
    "                continue\n",
    "            key = removeMultipleWhiteSpaces(relationSeed[0].strip())\n",
    "            value = removeMultipleWhiteSpaces(relationSeed[1].strip())\n",
    "            relationSeeds.append((key, value))\n",
    "    return set(relationSeeds)\n",
    "    \n",
    "\n",
    "def removeMultipleWhiteSpaces(s):\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "def getPageLocationAndSeed(d):\n",
    "    output = []\n",
    "    for pageDir in d:\n",
    "        pageLocation = pageDir + \"/page.html\"\n",
    "        seedLocation = pageDir + \"/seed\"\n",
    "        seed = readAllRelationSeeds(seedLocation)\n",
    "        output.append((pageLocation, seed))\n",
    "    return output\n",
    "\n",
    "\n",
    "#read the page from pageLocation\n",
    "def readPage(pageLocation):\n",
    "    htmlPageContent = \"\"\n",
    "    with open(pageLocation, 'r') as myfile:\n",
    "        htmlPageContent = myfile.read().strip()\n",
    "    return htmlPageContent\n",
    "\n",
    "def removeTerminatedAnd(s):\n",
    "    return re.sub(\"&amp;\", \"&\", s)\n",
    "\n",
    "\n",
    "\n",
    "#document processing logic at this stage is about removing multiple whitespaces into single one \n",
    "def preprocessDocument(document):\n",
    "    return removeTerminatedAnd(' '.join(document.split()))\n",
    "\n",
    "\n",
    "#get right contexts for each cluster    \n",
    "def getRightContexts(seedsLocations, htmlPageContent):\n",
    "    output = []\n",
    "    for (ls, le, rs, re) in seedsLocations:\n",
    "        start = le+rs\n",
    "        end = le+re\n",
    "        rc = htmlPageContent[end:min(len(htmlPageContent), end+100)].strip()\n",
    "        if len(rc)<=0:\n",
    "            continue\n",
    "        output.append(rc)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def getLeftContexts(seedsLocations, htmlPageContent):\n",
    "    output = []\n",
    "    for (start, end, x, y) in seedsLocations:\n",
    "        lc = htmlPageContent[(max(0, start-100)):start].strip()\n",
    "#         print(\"Seed is \")\n",
    "#         print(seed)\n",
    "#         print(str((htmlPageContent[start:end], htmlPageContent[end+x:end+y])))\n",
    "#         print(\"Left Context \")\n",
    "#         print(lc)\n",
    "        if len(lc)<=0:\n",
    "            continue\n",
    "        lc = lc[::-1]\n",
    "        output.append(lc)\n",
    "    return output\n",
    "    \n",
    "\n",
    "\n",
    "def getMiddleContexts(seedsLocations, pageContent):\n",
    "    output = []\n",
    "    for (x, y, start, end) in seedsLocations:\n",
    "        mid = pageContent[y:y+start].strip()\n",
    "#         print(\"mid is\" + mid)\n",
    "        if len(mid)<=0:\n",
    "            continue\n",
    "        output.append(mid)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getLeftBetweenRightContexts(pageContent, seed):\n",
    "    b = getEachSeedLocationsInPage(pageContent, seed)\n",
    "    output = []\n",
    "    leftContexts    = getLeftContexts(b, pageContent)\n",
    "    betweenContexts = getMiddleContexts(b, pageContent)\n",
    "    rightContexts   = getRightContexts(b, pageContent)\n",
    "    print(\"Seed is \" + str(seed))\n",
    "    print(\"right is \" + str(rightContexts))\n",
    "    return (leftContexts, betweenContexts, rightContexts)\n",
    "\n",
    "\n",
    "\n",
    "def getContextsForAllSeeds(pageContent, seed):\n",
    "    lout = []\n",
    "    bout = []\n",
    "    rout = []\n",
    "    for s in seed:\n",
    "        (lcPerS, bcPerS, rcPerS) = getLeftBetweenRightContexts(pageContent, s)\n",
    "#         if len(lcPerS)==0:\n",
    "#             print(\"Zero\\n\\n\\n\\n\\n\")\n",
    "#             print(\"Seed is \" + str(s))\n",
    "        lout.append(lcPerS)\n",
    "        bout.append(bcPerS)\n",
    "        rout.append(rcPerS)\n",
    "#         print(\"seed iss \" + str(s))\n",
    "#         print(\"ists patterns are \" + str(lcPerS))\n",
    "    return (lout, bout, rout)\n",
    "\n",
    "\n",
    "def printContextInformation(contexts, pageAndSeed, rev=False):\n",
    "    for index in range(0, len(pageAndSeed)):\n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "        (pageLocation, seed) = pageAndSeed[index]\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        contextPerPage = contexts[index]\n",
    "        print(\"For seed \" + str(seed))\n",
    "        print(\"Context is following: \" + pageLocation)# + \" number \" + str(contextPerPage))\n",
    "        for item in contextPerPage:\n",
    "            if rev==True:\n",
    "                item = item[::-1]\n",
    "            print(item)\n",
    "            print(\"---------------------\")\n",
    "            \n",
    "def printPerPageContextInfo(pageContent, contextPerPage, rev=False):\n",
    "    for item in contextPerPage:\n",
    "        if rev==True:\n",
    "            item = item[::-1]\n",
    "        print(item)\n",
    "        print(\"---------------------\")\n",
    "    \n",
    "\n",
    "    \n",
    "def getCommonPrefix(s1, s2):\n",
    "    l = [s1, s2]\n",
    "    return os.path.commonprefix(l)\n",
    "\n",
    "\n",
    "\n",
    "def insertCommonPrefix(results, commonPrefix):\n",
    "    if commonPrefix in results or len(commonPrefix)<=0:\n",
    "        return results\n",
    "    r = list(results)\n",
    "    for item in r:\n",
    "        if len(item)<len(commonPrefix) and commonPrefix.startswith(item):\n",
    "            results.remove(item)\n",
    "    r=list(results)\n",
    "    for item in r:\n",
    "        if len(item)>len(commonPrefix) and item.startswith(commonPrefix):\n",
    "            return results\n",
    "    results.add(commonPrefix)\n",
    "    return results\n",
    "\n",
    "def doPrefixIntersection(list1, list2):\n",
    "    results = set()\n",
    "    for item1 in list1:\n",
    "        commonPrefix = \"\"\n",
    "        for item2 in list2:\n",
    "            c = getCommonPrefix(item1, item2)\n",
    "            if len(c)>len(commonPrefix):\n",
    "                commonPrefix = c\n",
    "        results = insertCommonPrefix(results, commonPrefix)\n",
    "    return results\n",
    "\n",
    "\n",
    "def doIntersection(patterns):\n",
    "    if len(patterns)<=0:\n",
    "        return patterns\n",
    "    result = patterns[0]\n",
    "    for index in range(1, len(patterns)):\n",
    "#         print(\"Input\")\n",
    "#         print(result)\n",
    "#         print(patterns[index])\n",
    "        result = doPrefixIntersection(result, patterns[index])\n",
    "#         print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def printIn(l):\n",
    "    for item in l:\n",
    "        print(\"==========================\")\n",
    "        for val in item:\n",
    "            print(val)\n",
    "            print(\"---------------------\")\n",
    "\n",
    "def getLeftPatterns(leftContexts):\n",
    "#     print(\"Left full contexts are \")\n",
    "#     print(printIn(leftContexts))\n",
    "    lp = doIntersection(leftContexts)\n",
    "    results = []\n",
    "    for item in lp:\n",
    "        results.append(item[::-1]) \n",
    "    return results\n",
    "\n",
    "\n",
    "def getRightPatterns(rightContexts):\n",
    "    print(\"Right full contexts are \")\n",
    "    print(printIn(rightContexts))\n",
    "    return list(doIntersection(rightContexts))\n",
    "\n",
    "def getBetweenPatterns(rightContexts):\n",
    "    return list(doIntersection(rightContexts))\n",
    "\n",
    "def allPossibleTriples(lc, bc, rc):\n",
    "    output = []\n",
    "    for l in lc:\n",
    "        for b in bc:\n",
    "            for r in rc:\n",
    "                output.append((l, b, r))\n",
    "    return output\n",
    "                \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "#remove elements which were actually tag\n",
    "def isTag((a,b)):\n",
    "    if a.find(\"<\")!=-1 and a.find(\">\")!=-1 and b.find(\"<\")!=-1 and b.find(\">\")!=-1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#preprocess results before writing it to file\n",
    "def preprocessResults(output):\n",
    "    result = []\n",
    "    for o in output:\n",
    "        if isTag(o):\n",
    "            continue\n",
    "        result.append(o)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "    \n",
    "def getEachSeedLocationsInPage(document, (lSeed, rSeed), kvDiff=200):\n",
    "    lSeedLocations = [(i, i+len(lSeed)) for i in range(len(document)) if document.startswith(lSeed, i)]\n",
    "    docLength = len(document)\n",
    "    output = []\n",
    "    for (ls, le) in lSeedLocations:\n",
    "        subStr = document[le: min(le+200, docLength)]\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for m in re.finditer(re.escape(rSeed), subStr):\n",
    "            start = m.start()\n",
    "            end = m.end()\n",
    "        loc = start\n",
    "        if loc==-1:\n",
    "            continue\n",
    "        rs = loc\n",
    "        re = loc + len(rSeed)\n",
    "        output.append((ls, le, rs, re))\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#Pattern is (l, m, r) and match them to htmlPageContent\n",
    "def findRelationSetwrtPattern(htmlPageContent, (l, mid, r)):\n",
    "    #for each start location of pattern find its end\n",
    "    #for each end page find the pattern right\n",
    "    #extract everything till that point\n",
    "    #after extraction move one point above that pattern string\n",
    "    results = []\n",
    "    for m in re.finditer(re.escape(l), htmlPageContent):\n",
    "        start = m.start()\n",
    "        end = m.end()\n",
    "        rightPage = htmlPageContent[end:]\n",
    "        rightLoc  = rightPage.find(r)\n",
    "        if rightLoc==-1:\n",
    "            break\n",
    "        substr = rightPage[:rightLoc]\n",
    "#         print(\"substr is \" + substr)\n",
    "        mLoc = substr.find(mid)\n",
    "#         print(\"mloc is \" + str(mLoc))\n",
    "        if mLoc==-1:\n",
    "            continue\n",
    "        e1 = substr[:mLoc].strip()\n",
    "        e2 = substr[mLoc+len(mid):].strip()\n",
    "#         print(e1)\n",
    "#         print(e2)\n",
    "        if len(e1)>1 and len(e2)>=1 and len(e1)<100 and len(e2)<500:\n",
    "#             print(\"Appending \" + str((e1, e2)))\n",
    "            results.append((e1, e2))\n",
    "    return set(results)\n",
    "\n",
    "\n",
    "\n",
    "#input: all the pattern found and new html page\n",
    "#output: extract set of elements from the page that are in our set(whose definition we know)\n",
    "def extractSet(patterns, htmlPageContent):\n",
    "    output = []\n",
    "    for pattern in patterns:\n",
    "        output.extend(findRelationSetwrtPattern(htmlPageContent, pattern))\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def doProcessingWithoutClass(s, regExpIn, regExpOut):\n",
    "    allManaged =  re.sub(regExpIn, regExpOut, s)\n",
    "    removeQuoteIn = r'\"[^\"]*\"'\n",
    "    removeQuoteOut = r'\"\"'\n",
    "    return re.sub(removeQuoteIn, removeQuoteOut, allManaged)\n",
    "#     i = \"class[\\s]*=[\\s]*\"\n",
    "#     o       = \"class=\"\n",
    "#     s = re.sub(i, o, s)\n",
    "#     i = \"([^class])=\\\"[^\\\"]*\\\"\"\n",
    "#     o = \"\\\\1=\\\"\\\"\"\n",
    "#     return re.sub(i, o, s)\n",
    "\n",
    "\n",
    "\n",
    "def getLastWordWithoutEqualSign(leftContext):\n",
    "    words = leftContext.strip().split(\" \")\n",
    "    totalWords = len(words)\n",
    "    if len(words)<2:\n",
    "        return \"\"\n",
    "    else:\n",
    "        if words[totalWords-1]==\"=\":\n",
    "            return words[totalWords-2]\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "def getSpecialWords(document, seedsSet):\n",
    "    totalLength = len(document)\n",
    "    specialWords = []\n",
    "    for s in seedsSet:\n",
    "        allSeedPositions = getEachSeedLocationsInPage(document, s)\n",
    "        for (start, end, rOffsetStart, rOffsetEnd) in allSeedPositions:\n",
    "            prevLoc = start-1\n",
    "            nextLoc = end\n",
    "            prevLoc2 = end+rOffsetStart-1\n",
    "            nextLoc2 = end+rOffsetEnd+1\n",
    "            if prevLoc>=0 and nextLoc<totalLength:\n",
    "                prevQuot = document[prevLoc]\n",
    "                nextQuot  = document[nextLoc]\n",
    "#                 print(prevQuot + \" \" + nextQuot)\n",
    "                if prevQuot==\"\\\"\" and nextQuot==\"\\\"\":\n",
    "                    leftContext = document[max(0, prevLoc-100):prevLoc]\n",
    "                    lastWord = getLastWordWithoutEqualSign(leftContext)\n",
    "                    if len(lastWord)>0:\n",
    "                        specialWords.append(lastWord)\n",
    "            if prevLoc2>=0 and nextLoc2<totalLength:\n",
    "                prevQuot = document[prevLoc2]\n",
    "                nextQuot  = document[nextLoc2]\n",
    "#                 print(prevQuot + \" \" + nextQuot)\n",
    "                if prevQuot==\"\\\"\" and nextQuot==\"\\\"\":\n",
    "                    leftContext = document[max(0, prevLoc2-100):prevLoc2]\n",
    "                    lastWord = getLastWordWithoutEqualSign(leftContext)\n",
    "                    if len(lastWord)>0:\n",
    "                        specialWords.append(lastWord)\n",
    "\n",
    "    return specialWords\n",
    "\n",
    "\n",
    "\n",
    "def createRegExpFromWordStr(wordsStr):\n",
    "#     wordsStr = getWordsStr(words)\n",
    "#     print(\"wordsstr is \" + wordsStr)\n",
    "    return (\"(\" + wordsStr +\")[\\s]*=[\\s]*\\\"([^\\\"]*)\\\"\", \"\\\\1=\\\\2\")\n",
    "\n",
    "\n",
    "\n",
    "def getWordsStr(words):\n",
    "    out = words[0]\n",
    "    if len(words)==1:\n",
    "        return out\n",
    "    else:\n",
    "        for index in range(1, len(words)):\n",
    "            out+=\"|\"+words[index]\n",
    "    print(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def getAllSpecialWordsAsString(pageLocationAndSeed):\n",
    "    specialWords = []\n",
    "    specialWords.append(\"class\")\n",
    "    for (pageLocation, seeds) in pageLocationAndSeed:\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        specialWords.extend(getSpecialWords(pageContent, seeds))\n",
    "    specialWords = list(set(specialWords))\n",
    "    return getWordsStr(specialWords)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getAllPatternsByPlainStringMatch(corpusLocation):\n",
    "    directories             = getAllDirectoriesInLocation(corpusLocation)\n",
    "    (trainDirs, testDirs)   = trainTestSplit(directories)\n",
    "    pageLocationsAndSeed    = getPageLocationAndSeed(trainDirs)\n",
    "    testPageLocationAndSeed = getPageLocationAndSeed(testDirs)\n",
    "    leftContexts    = []\n",
    "    betweenContexts = []\n",
    "    rightContexts   = []\n",
    "    for (pageLocation, seed) in pageLocationsAndSeed:\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        (lcPerPage, bcPerPage, rcPerPage) = getContextsForAllSeeds(pageContent, seed)\n",
    "#         (leftContextsPerPage, rightContextsPerPage) = getContextsForAllSeeds(pageContent, seed)\n",
    "        leftContexts.extend(lcPerPage)\n",
    "        betweenContexts.extend(bcPerPage)\n",
    "        rightContexts.extend(rcPerPage)\n",
    "        print(\"Page is \" + str(pageLocation))\n",
    "        print(\"texts are \")\n",
    "        print(rcPerPage)\n",
    "    printContextInformation(rightContexts, pageLocationsAndSeed)\n",
    "    leftPatterns     = getLeftPatterns(leftContexts)\n",
    "    betweenPatterns  = getBetweenPatterns(betweenContexts)\n",
    "    rightPatterns    = getRightPatterns(rightContexts)\n",
    "    print(\"Left Patterns\")\n",
    "    print(leftPatterns)\n",
    "    print(\"Between\")\n",
    "    print(betweenPatterns)\n",
    "    print(\"Right\")\n",
    "    print(rightPatterns)\n",
    "    patterns         = allPossibleTriples(leftPatterns, betweenPatterns, rightPatterns)\n",
    "    print(patterns)\n",
    "    recall = 0\n",
    "    extraResults = 0\n",
    "    for (pageLocation, seed) in testPageLocationAndSeed:\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        resultsPerPage = preprocessResults(list(extractSet(patterns, pageContent)))\n",
    "        flag=True\n",
    "        for s in seed:\n",
    "            if not s in resultsPerPage:\n",
    "                print(pageLocation)\n",
    "                print(\"Following: \")\n",
    "                print(s)\n",
    "                flag=False\n",
    "        if flag==True:\n",
    "            recall+=1\n",
    "#         else:\n",
    "#             print(\"Seed results were\")\n",
    "#             print(seed)\n",
    "#             print(\"resultsperpage is \")\n",
    "#             print(resultsPerPage)\n",
    "        extraElements = len(resultsPerPage) - len(seed)\n",
    "        if extraElements>1:\n",
    "            seedsLocation = os.path.dirname(pageLocation) + \"/seed\"\n",
    "            allSeeds = readAllRelationSeeds(seedsLocation)\n",
    "            totalCount = len(resultsPerPage)\n",
    "            allSeedsCount = len(list(allSeeds.intersection(set(resultsPerPage))))\n",
    "            extracount = totalCount - allSeedsCount\n",
    "            extraResults += extracount\n",
    "            print(pageLocation)\n",
    "            print(\"Extra elements are \")\n",
    "            print(set(resultsPerPage)-seed)\n",
    "    seedsMissed = len(testPageLocationAndSeed)-recall\n",
    "    return (patterns, seedsMissed, extraResults, len(testDirs))\n",
    "    \n",
    "getAllPatternsByPlainStringMatch(\"tablesData/flipkart/corpus\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getAllPatternsByRetainingOnlyClassValue(corpusLocation):\n",
    "    directories             = getAllDirectoriesInLocation(corpusLocation)\n",
    "    (trainDirs, testDirs)   = trainTestSplit(directories)\n",
    "    pageLocationsAndSeed    = getPageLocationAndSeed(trainDirs)\n",
    "    testPageLocationAndSeed = getPageLocationAndSeed(testDirs)\n",
    "    specialWordsString      = getAllSpecialWordsAsString(pageLocationsAndSeed)\n",
    "    (regExpIn, regExpOut)   = createRegExpFromWordStr(specialWordsString)\n",
    "    leftContexts    = []\n",
    "    betweenContexts = []\n",
    "    rightContexts   = []\n",
    "    for (pageLocation, seed) in pageLocationsAndSeed:\n",
    "        pageContent = doProcessingWithoutClass(preprocessDocument(readPage(pageLocation)), regExpIn, regExpOut)\n",
    "        (lcPerPage, bcPerPage, rcPerPage) = getContextsForAllSeeds(pageContent, seed)\n",
    "#         (leftContextsPerPage, rightContextsPerPage) = getContextsForAllSeeds(pageContent, seed)\n",
    "        leftContexts.extend(lcPerPage)\n",
    "        betweenContexts.extend(bcPerPage)\n",
    "        rightContexts.extend(rcPerPage)\n",
    "    leftPatterns     = getLeftPatterns(leftContexts)\n",
    "    betweenPatterns  = getBetweenPatterns(betweenContexts)\n",
    "    rightPatterns    = getRightPatterns(rightContexts)\n",
    "    patterns         = allPossibleTriples(leftPatterns, betweenPatterns, rightPatterns)\n",
    "    print(patterns)\n",
    "    recall = 0\n",
    "    extraResults = 0\n",
    "    for (pageLocation, seed) in testPageLocationAndSeed:\n",
    "        pageContent = doProcessingWithoutClass(preprocessDocument(readPage(pageLocation)), regExpIn, regExpOut)\n",
    "        resultsPerPage = preprocessResults(list(extractSet(patterns, pageContent)))\n",
    "        flag=True\n",
    "        for s in seed:\n",
    "            if not s in resultsPerPage:\n",
    "                print(pageLocation)\n",
    "                print(\"Following: \")\n",
    "                print(s)\n",
    "                flag=False\n",
    "        if flag==True:\n",
    "            recall+=1\n",
    "#         else:\n",
    "#             print(\"Seed results were\")\n",
    "#             print(seed)\n",
    "#             print(\"resultsperpage is \")\n",
    "#             print(resultsPerPage)\n",
    "        extraElements = len(resultsPerPage) - len(seed)\n",
    "        if extraElements>1:\n",
    "            seedsLocation = os.path.dirname(pageLocation) + \"/seed\"\n",
    "            allSeeds = readAllRelationSeeds(seedsLocation)\n",
    "            totalCount = len(resultsPerPage)\n",
    "            allSeedsCount = len(list(allSeeds.intersection(set(resultsPerPage))))\n",
    "            extracount = totalCount - allSeedsCount\n",
    "            extraResults += extracount\n",
    "            print(pageLocation)\n",
    "            print(\"Extra elements are \")\n",
    "            print(set(resultsPerPage)-seed)\n",
    "    seedsMissed = len(testPageLocationAndSeed)-recall\n",
    "    return (patterns, seedsMissed, extraResults, len(testDirs), specialWordsString)\n",
    "# getAllPatternsByRetainingOnlyClassValue(\"tablesData/amazon\")\n",
    "\n",
    "\n",
    "def getPatternStore(eCommerceDataSetLocation):\n",
    "    allWebsites = getAllDirectoriesInLocation(eCommerceDataSetLocation)\n",
    "#     print(\"All websites are \" + str(allWebsites))\n",
    "    patternsStore = []\n",
    "    for website in allWebsites:\n",
    "        corpusLocation = website + \"/corpus\"\n",
    "        websiteName = os.path.basename(website)\n",
    "        (plainPatterns, plainMissed, plainJunkCount, plainTotal)           = getAllPatternsByPlainStringMatch(corpusLocation)\n",
    "        (noValPatterns, noValMissed, noValJunkCount, noValTotal, wordsStr) = getAllPatternsByRetainingOnlyClassValue(corpusLocation)\n",
    "#         print(website)\n",
    "#         print(\"Plain missed is \" + str(plainMissed))\n",
    "#         print(\"junk missed is \" + str(noValMissed))\n",
    "        if plainMissed < noValMissed:\n",
    "            patterns = (websiteName, \"plainPattern\", plainPatterns, plainMissed, plainJunkCount, plainTotal)\n",
    "#             print(plainPatterns)\n",
    "        elif plainMissed > noValMissed:\n",
    "            patterns = (websiteName, \"noValuePattern_\"+wordsStr, noValPatterns, noValMissed, noValJunkCount, noValTotal)\n",
    "        else:\n",
    "            if plainJunkCount<=noValJunkCount:\n",
    "#                 print(\"Here\")\n",
    "                patterns = (websiteName, \"plainPattern\", plainPatterns, plainMissed, plainJunkCount, plainTotal)\n",
    "            else:\n",
    "#                 print(\"There\")\n",
    "                patterns = (websiteName, \"noValuePattern_\"+wordsStr, noValPatterns, noValMissed, noValJunkCount, noValTotal)\n",
    "#         if plainMissed < noValMissed:\n",
    "#             patterns = (websiteName, \"plainPattern\", plainPatterns, plainMissed, plainJunkCount, plainTotal)\n",
    "# #             print(plainPatterns)\n",
    "#         else:\n",
    "#             patterns = (websiteName, \"noValuePattern_\"+wordsStr, noValPatterns, noValMissed, noValJunkCount, noValTotal)\n",
    "        patternsStore.append(patterns)\n",
    "#     for p in patternsStore:\n",
    "#         print(p)\n",
    "    return patternsStore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def writeListToFile(loc, l):\n",
    "    with open(loc, 'w') as f:\n",
    "        for item in l:\n",
    "            f.write(item+\"\\n\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# getPatternStore(\"tablesData\")\n",
    "\n",
    "def writeRelationPatternsToFile(fileLocation, productPatterns):\n",
    "    header = \"GroupId\\tWebsiteName\\tPatternType\\tMissed\\tJunk\\tOutof\\tLeftPattern\\tMiddlePattern\\tRightPattern\"\n",
    "    groupId = 1\n",
    "    output = []\n",
    "    output.append(header)\n",
    "    for (website, pType, patterns, missed, junk, total) in productPatterns:\n",
    "        rowPrefix = str(groupId) + \"\\t\" + website + \"\\t\" + pType\n",
    "        rowPrefix+=\"\\t\" + str(missed) + \"\\t\" + str(junk) + \"\\t\" + str(total)\n",
    "        for (l, m, r) in patterns:\n",
    "            row = rowPrefix + \"\\t\" + l + \"\\t\" + m + \"\\t\" + r\n",
    "            output.append(row)\n",
    "        groupId+=1\n",
    "#     print(\"output is \")\n",
    "#     for item in output:\n",
    "#         print(item)\n",
    "    writeListToFile(fileLocation, output)\n",
    "    print(\"Output written at location: \" + fileLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter e-commerce data location: \n",
      "tablesData\n",
      "Enter outputLocation\n",
      "newPatternsLearnt\n",
      "Patterns will be found at newPatternsLearnt/tablePatterns.tsv\n",
      "[]\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Composition', 'Aloe')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Container Type', 'Plastic Bottle')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Model Name', 'Professionnel Xtenso Care Shampoo 230 ml')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Sales Package', '1 Shampoo')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Hair Texture', 'Fine')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Sulfate Free', 'Yes')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Pockets', '2 Pockets at Front')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Color', 'Blue, Dark Blue')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Fabric Care', 'Machine Wash as per Tag')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Pattern', 'Printed')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Type', 'Sports Jacket')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Fabric', 'Cotton Polyester')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Style Code', '83063302new navy')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Model Details', 'This model has a Height of 6 feet 1 inches and is wearing a Jacket of Size M')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Reversible', 'No')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Ideal For', \"Men's\")\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Hooded', 'Yes')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Closure', 'Zipper')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Cuff', 'Ribbed Cuffs')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Sleeve', 'Full Sleeve')\n",
      "tablesData/flipkart/corpus/page2/page.html\n",
      "Following: \n",
      "('Sales Package', 'Pack of 2')\n",
      "tablesData/flipkart/corpus/page2/page.html\n",
      "Following: \n",
      "('Model Name', 'DARBAR-PANAL')\n",
      "tablesData/flipkart/corpus/page2/page.html\n",
      "Following: \n",
      "('Model Number', '2DARBAR-2')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Suitable For', 'Western Wear')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Fabric', 'Cotton Polyester Blend')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Style Code', 'GRINPRINT-C')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Fit', 'Slim')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Reversible', 'No')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Sleeve', 'Half Sleeve')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Brand Fit', 'Slim')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Sleeve Type', 'Narrow')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Size', 'L')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Neck Type', 'Polo Neck')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Pack of', '1')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Fabric Care', 'Wash with like colors')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Ideal For', 'Men')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Sales Package', '1 t-shirt')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Pattern', 'Printed, Solid')\n",
      "[]\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Composition', 'Aloe')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Container Type', 'Plastic Bottle')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Model Name', 'Professionnel Xtenso Care Shampoo 230 ml')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Sales Package', '1 Shampoo')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Hair Texture', 'Fine')\n",
      "tablesData/flipkart/corpus/page9/page.html\n",
      "Following: \n",
      "('Sulfate Free', 'Yes')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Pockets', '2 Pockets at Front')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Color', 'Blue, Dark Blue')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Fabric Care', 'Machine Wash as per Tag')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Pattern', 'Printed')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Type', 'Sports Jacket')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Fabric', 'Cotton Polyester')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Style Code', '83063302new navy')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Model Details', 'This model has a Height of 6 feet 1 inches and is wearing a Jacket of Size M')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Reversible', 'No')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Ideal For', \"Men's\")\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Hooded', 'Yes')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Closure', 'Zipper')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Cuff', 'Ribbed Cuffs')\n",
      "tablesData/flipkart/corpus/page10/page.html\n",
      "Following: \n",
      "('Sleeve', 'Full Sleeve')\n",
      "tablesData/flipkart/corpus/page2/page.html\n",
      "Following: \n",
      "('Sales Package', 'Pack of 2')\n",
      "tablesData/flipkart/corpus/page2/page.html\n",
      "Following: \n",
      "('Model Name', 'DARBAR-PANAL')\n",
      "tablesData/flipkart/corpus/page2/page.html\n",
      "Following: \n",
      "('Model Number', '2DARBAR-2')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Suitable For', 'Western Wear')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Fabric', 'Cotton Polyester Blend')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Style Code', 'GRINPRINT-C')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Fit', 'Slim')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Reversible', 'No')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Sleeve', 'Half Sleeve')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Brand Fit', 'Slim')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Sleeve Type', 'Narrow')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Size', 'L')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Neck Type', 'Polo Neck')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Pack of', '1')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Fabric Care', 'Wash with like colors')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Ideal For', 'Men')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Sales Package', '1 t-shirt')\n",
      "tablesData/flipkart/corpus/page4/page.html\n",
      "Following: \n",
      "('Pattern', 'Printed, Solid')\n",
      "Pattern store is \n",
      "[('flipkart', 'plainPattern', [], 4, 0, 4)]\n",
      "Output written at location: newPatternsLearnt/tablePatterns.tsv\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter e-commerce data location: \")\n",
    "eCommerceDataLocation = raw_input()\n",
    "print(\"Enter outputLocation\")\n",
    "outputLocation = raw_input()\n",
    "outputLocation+=\"/tablePatterns.tsv\"\n",
    "print(\"Patterns will be found at \" + str(outputLocation))\n",
    "patternsStore = getPatternStore(eCommerceDataLocation)\n",
    "print(\"Pattern store is \")\n",
    "print(patternsStore)\n",
    "writeRelationPatternsToFile(outputLocation, patternsStore)\n",
    "#categoryData\n",
    "#featureSpecificationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ications_section_1\" class=\"a-keyvalue a-spacing-mini\"> <tbody><tr> <th class=\"a-span5 a-size-base\">\"\n"
     ]
    }
   ],
   "source": [
    "l = \"\\\">\\\"esab-ezis-a 5naps-a\\\"=ssalc ht< >rt<>ydobt< >\\\"inim-gnicaps-a eulavyek-a\\\"=ssalc \\\"1_noitces_snoitaci\"\n",
    "print(l[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\'>\"lebal\"=ssalc dt<>rt< >ydobt< >\"0\"=redrob \"0\"=gniddapllec \"0\"=gnicapsllec elbat< >\";kcolb:yalpsid\"=\\'']\n",
      "['\\'>\"yradnoces-roloc-a esab-ezis-a\"=ssalc naps< >\"loc_tsrif_elbat_nosirapmoc nmuloc_eman_etubirtta_nosi\\'', '\\'>\"lebal\"=ssalc dt<>rt< >rt/<>dt/<senohpdaeH>\"eulav\"=ssalc dt<>dt/<sliateD oiduA>\"lebal\"=ssalc dt<>rt\\'']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['> <tr><td class=\"label\">\\'']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [\"'>\\\"lebal\\\"=ssalc dt<>rt< >ydobt< >\\\"0\\\"=redrob \\\"0\\\"=gniddapllec \\\"0\\\"=gnicapsllec elbat< >\\\";kcolb:yalpsid\\\"='\"]\n",
    "l2 = [\"'>\\\"yradnoces-roloc-a esab-ezis-a\\\"=ssalc naps< >\\\"loc_tsrif_elbat_nosirapmoc nmuloc_eman_etubirtta_nosi'\", \"'>\\\"lebal\\\"=ssalc dt<>rt< >rt/<>dt/<senohpdaeH>\\\"eulav\\\"=ssalc dt<>dt/<sliateD oiduA>\\\"lebal\\\"=ssalc dt<>rt'\"]\n",
    "print(l1)\n",
    "print(l2)\n",
    "l = [l1, l2]\n",
    "getLeftPatterns(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
