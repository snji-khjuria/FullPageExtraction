{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the corpus directory out of which we'll learn patterns: \n",
      "Corpus directory is categoryData/flipkart/corpus\n",
      "Train Files are ['categoryData/flipkart/corpus/page1', 'categoryData/flipkart/corpus/page6', 'categoryData/flipkart/corpus/page7', 'categoryData/flipkart/corpus/page5', 'categoryData/flipkart/corpus/page8', 'categoryData/flipkart/corpus/page3']\n",
      "Test files are ['categoryData/flipkart/corpus/page9', 'categoryData/flipkart/corpus/page10', 'categoryData/flipkart/corpus/page2', 'categoryData/flipkart/corpus/page4']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "#corpus directory for flipkart\n",
    "# productNameData/flipkart/corpus\n",
    "print(\"Enter the corpus directory out of which we'll learn patterns: \")\n",
    "# corpusDirectory = raw_input()\n",
    "corpusDirectory = \"categoryData/flipkart/corpus\"\n",
    "print(\"Corpus directory is \" + corpusDirectory)\n",
    "directories = getAllDirectoriesInLocation(corpusDirectory)\n",
    "(trainDirs, testDirs) = trainTestSplit(directories)\n",
    "print(\"Train Files are \" + str(trainDirs))\n",
    "print(\"Test files are \" + str(testDirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "#do train/test split\n",
    "def trainTestSplit(files):\n",
    "    sixtyPercent = int(len(files)*(0.6))\n",
    "    if sixtyPercent<4:\n",
    "        print(\"We won't be able to report accuracy of patterns\")\n",
    "        return (files, [])\n",
    "    else:\n",
    "        return (files[:sixtyPercent], files[sixtyPercent:])\n",
    "\n",
    "def getAllDirectoriesInLocation(loc):\n",
    "    listOfSubDir = [loc+\"/\"+f for f in os.listdir(loc)]\n",
    "    return listOfSubDir\n",
    "\n",
    "def removeMultipleWhiteSpaces(s):\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "def readAllSeedsAsSet(fileLocation):\n",
    "    with open(fileLocation) as f:\n",
    "        content = f.readlines()\n",
    "    content = [removeMultipleWhiteSpaces(x.strip()) for x in content]\n",
    "    return set(content)\n",
    "\n",
    "def getCategorySeeds(fileLocation):\n",
    "    with open(fileLocation) as f:\n",
    "        content = f.readlines()\n",
    "    content = [removeMultipleWhiteSpaces(x.strip()) for x in content] \n",
    "#     print(\"content is \" + str(content))\n",
    "    return content[1:len(content)-1]\n",
    "\n",
    "\n",
    "def getPageLocationAndSeed(d):\n",
    "    output = []\n",
    "    for pageDir in d:\n",
    "        pageLocation = pageDir + \"/page.html\"\n",
    "        seedLocation = pageDir + \"/seed\"\n",
    "        seed = getCategorySeeds(seedLocation)\n",
    "        output.append((pageLocation, seed))\n",
    "    return output\n",
    "#read the page from pageLocation\n",
    "def readPage(pageLocation):\n",
    "    htmlPageContent = \"\"\n",
    "    with open(pageLocation, 'r') as myfile:\n",
    "        htmlPageContent = myfile.read().strip()\n",
    "    return htmlPageContent\n",
    "\n",
    "def removeTerminatedAnd(s):\n",
    "    return re.sub(\"&amp;\", \"&\", s)\n",
    "\n",
    "\n",
    "\n",
    "#document processing logic at this stage is about removing multiple whitespaces into single one \n",
    "def preprocessDocument(document):\n",
    "    return removeTerminatedAnd(' '.join(document.split()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getLeftAndRightContexts(pageContent, seed):\n",
    "    b = getEachSeedLocationsInPage(pageContent, seed)\n",
    "    output = []\n",
    "    totalLength = len(pageContent)\n",
    "    leftContexts = []\n",
    "    rightContexts = []\n",
    "    for (s, e) in b:\n",
    "        leftContext = pageContent[max(0, s-100):s]\n",
    "        leftContext = leftContext[::-1]\n",
    "        rightContext = pageContent[e:min(totalLength, e+100)]\n",
    "        leftContexts.append(leftContext)\n",
    "        rightContexts.append(rightContext)\n",
    "    return (leftContexts, rightContexts)\n",
    "    \n",
    "    \n",
    "#find all start, end pairs of particular key\n",
    "def getAllStartEndPairs(document, key):\n",
    "    keyLength = len(key)\n",
    "    return [(i, i+keyLength) for i in range(len(document)) if document.startswith(key, i)]\n",
    " \n",
    "    \n",
    "#find seeds for one particular seed(at this stage call only getAllStartEndPairs())\n",
    "def getEachSeedLocationsInPage(htmlPageContent, seed):\n",
    "    return getAllStartEndPairs(htmlPageContent, seed)\n",
    "\n",
    "def printContextInformation(contexts, pageAndSeed, rev=False):\n",
    "    for index in range(0, len(pageAndSeed)):\n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "        (pageLocation, seed) = pageAndSeed[index]\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        contextPerPage = contexts[index]\n",
    "        print(\"For seed \" + str(seed))\n",
    "        print(\"Context is following: \" + pageLocation)# + \" number \" + str(contextPerPage))\n",
    "        for item in contextPerPage:\n",
    "            if rev==True:\n",
    "                item = item[::-1]\n",
    "            print(item)\n",
    "            print(\"---------------------\")\n",
    "\n",
    "def getCommonPrefix(s1, s2):\n",
    "    l = [s1, s2]\n",
    "    return os.path.commonprefix(l)\n",
    "\n",
    "\n",
    "\n",
    "def insertCommonPrefix(results, commonPrefix):\n",
    "    if commonPrefix in results or len(commonPrefix)<=0:\n",
    "        return results\n",
    "    r = list(results)\n",
    "    for item in r:\n",
    "        if len(item)<len(commonPrefix) and commonPrefix.startswith(item):\n",
    "            results.remove(item)\n",
    "    r=list(results)\n",
    "    for item in r:\n",
    "        if len(item)>len(commonPrefix) and item.startswith(commonPrefix):\n",
    "            return results\n",
    "    results.add(commonPrefix)\n",
    "    return results\n",
    "\n",
    "def doPrefixIntersection(list1, list2):\n",
    "    results = set()\n",
    "    for item1 in list1:\n",
    "        commonPrefix = \"\"\n",
    "        for item2 in list2:\n",
    "            c = getCommonPrefix(item1, item2)\n",
    "            if len(c)>len(commonPrefix):\n",
    "                commonPrefix = c\n",
    "        results = insertCommonPrefix(results, commonPrefix)\n",
    "    return results\n",
    "\n",
    "\n",
    "def doIntersection(patterns):\n",
    "    if len(patterns)<=0:\n",
    "        return patterns\n",
    "    result = patterns[0]\n",
    "    for index in range(1, len(patterns)):\n",
    "        result = doPrefixIntersection(result, patterns[index])\n",
    "    return result\n",
    "\n",
    "\n",
    "def getLeftPatterns(leftContexts):\n",
    "    lp = doIntersection(leftContexts)\n",
    "    results = []\n",
    "    for item in lp:\n",
    "        results.append(item[::-1]) \n",
    "    return results\n",
    "\n",
    "\n",
    "def getRightPatterns(rightContexts):\n",
    "    return list(doIntersection(rightContexts))\n",
    "\n",
    "\n",
    "def allPossiblePairs(leftPatterns, rightPatterns):\n",
    "    patterns = []\n",
    "    for lp in leftPatterns:\n",
    "        for rp in rightPatterns:\n",
    "            patterns.append((lp, rp))\n",
    "    return patterns\n",
    "\n",
    "#Pattern is (l, r) and match them to htmlPageContent\n",
    "def findEntitySetwrtPattern(htmlPageContent, (l, r)):\n",
    "    #for each start location of pattern find its end\n",
    "    #for each end page find the pattern right\n",
    "    #extract everything till that point\n",
    "    #after extraction move one point above that pattern string\n",
    "    results = []\n",
    "    for m in re.finditer(re.escape(l), htmlPageContent):\n",
    "        start = m.start()\n",
    "        end = m.end()\n",
    "        rightPage = htmlPageContent[end:]\n",
    "        rightLoc  = rightPage.find(r)\n",
    "        if rightLoc==-1:\n",
    "            break\n",
    "        element = rightPage[:rightLoc]\n",
    "        if len(element)>1 and len(element)<500:\n",
    "            results.append(element)\n",
    "    return set(results)\n",
    "\n",
    "\n",
    "def extractSet(patterns, htmlPageContent):\n",
    "    output = []\n",
    "    for pattern in patterns:\n",
    "        output.extend(findEntitySetwrtPattern(htmlPageContent, pattern))\n",
    "    return set(output)\n",
    "\n",
    "def filterPatterns(pageLocationAndSeeds, patterns, applyClass=False):\n",
    "    seedsSet = set()\n",
    "    for (pageLoc, seed) in pageLocationAndSeeds:\n",
    "        for s in seed:\n",
    "            seedsSet.add(s)\n",
    "    seeds = list(seedsSet)\n",
    "    patternSuccess = []\n",
    "    for index in range(0, len(patterns)):\n",
    "        patternSuccess.append(0)\n",
    "    for index in range(0, len(patterns)):\n",
    "        for (pageLocation, seed) in pageLocationAndSeeds:\n",
    "            pageContent = preprocessDocument(readPage(pageLocation))\n",
    "            if applyClass == True:\n",
    "                pageContent = doProcessingWithoutClass(pageContent)\n",
    "            resultsFound = extractSet([patterns[index]], pageContent)\n",
    "            flag = True\n",
    "            for s in seed:\n",
    "                if not s in resultsFound:\n",
    "                    flag=False\n",
    "            if flag==True:\n",
    "                patternSuccess[index]+=1\n",
    "                \n",
    "    output = []\n",
    "    for index in range(0, len(patterns)):\n",
    "        if patternSuccess[index]>0:\n",
    "            output.append(patterns[index])\n",
    "    return output\n",
    "\n",
    "\n",
    "#remove elements which were actually tag\n",
    "def isTag(s):\n",
    "    if s.find(\"<\")!=-1 and s.find(\">\")!=-1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#preprocess results before writing it to file\n",
    "def preprocessResults(output):\n",
    "    result = []\n",
    "    for o in output:\n",
    "        if isTag(o):\n",
    "            continue\n",
    "        result.append(o)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def doProcessingWithoutClass(s, words):\n",
    "    i = \"class[\\s]*=[\\s]*\"\n",
    "    o       = \"class=\"\n",
    "    s = re.sub(i, o, s)\n",
    "    i = \"([^class])=\\\"[^\\\"]*\\\"\"\n",
    "    o = \"\\\\1=\\\"\\\"\"\n",
    "    return re.sub(i, o, s)\n",
    "\n",
    "def getContextsForAllSeeds(pageContent, seed):\n",
    "    lout = []\n",
    "    rout = []\n",
    "    for s in seed:\n",
    "        (lcPerS, rcPerS) = getLeftAndRightContexts(pageContent, s)\n",
    "        lout.append(lcPerS)\n",
    "        rout.append(rcPerS)\n",
    "    return (lout, rout)\n",
    "\n",
    "def getAllPatternsByPlainStringMatch(corpusLocation):\n",
    "    directories             = getAllDirectoriesInLocation(corpusLocation)\n",
    "    (trainDirs, testDirs)   = trainTestSplit(directories)\n",
    "#     print(trainDirs)\n",
    "    pageLocationsAndSeed    = getPageLocationAndSeed(trainDirs)\n",
    "    testPageLocationAndSeed = getPageLocationAndSeed(testDirs)\n",
    "    leftContexts  = []\n",
    "    rightContexts = []\n",
    "    for (pageLocation, seed) in pageLocationsAndSeed:\n",
    "#         print(\"pageLocation is \" + pageLocation)\n",
    "#         print(\"seed is \")\n",
    "#         print(seed)\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        (leftContextsPerPage, rightContextsPerPage) = getContextsForAllSeeds(pageContent, seed)\n",
    "        if [] in leftContextsPerPage:\n",
    "            print(pageLocation + \" has some empty seed\")\n",
    "#             error\n",
    "#         (leftContextsPerPage, rightContextsPerPage) = getLeftAndRightContexts(pageContent, seed)\n",
    "        leftContexts.extend(leftContextsPerPage)\n",
    "        rightContexts.extend(rightContextsPerPage)\n",
    "#     printContextInformation(leftContexts, pageLocationsAndSeed, True)\n",
    "#     printContextInformation(rightContexts, pageLocationsAndSeed)\n",
    "#     print(\"Total left contexts \")\n",
    "#     print(leftContexts)\n",
    "    leftPatterns = getLeftPatterns(leftContexts)\n",
    "    rightPatterns = getRightPatterns(rightContexts)\n",
    "#     print(leftPatterns)\n",
    "#     print(rightPatterns)\n",
    "    \n",
    "#     print(\"Left patterns are \" + str(leftPatterns))\n",
    "#     print(\"Right patterns are \" + str(rightPatterns))\n",
    "    patterns = allPossiblePairs(leftPatterns, rightPatterns)\n",
    "#     print(\"All possible patterns: \")\n",
    "#     print(patterns)\n",
    "    patterns = filterPatterns(pageLocationsAndSeed, patterns)\n",
    "    #TODO if number of patterns are empty go for empty class thing\n",
    "#     print(\"Final Patterns \")\n",
    "#     print(patterns)\n",
    "    recall = 0\n",
    "    extraResults = 0\n",
    "    for (pageLocation, seed) in testPageLocationAndSeed:\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        resultsPerPage = preprocessResults(list(extractSet(patterns, pageContent)))\n",
    "#         resultsPerPage = list(set(resultsPerPage))\n",
    "        flag=True\n",
    "        for s in seed:\n",
    "            if not s in resultsPerPage:\n",
    "                flag=False\n",
    "        if flag==True:\n",
    "            recall+=1\n",
    "#         if seed in resultsPerPage:\n",
    "#             recall += 1\n",
    "        extraElements = len(resultsPerPage) - len(seed)\n",
    "        if extraElements>1:\n",
    "            seedsLocation = os.path.dirname(pageLocation) + \"/seed\"\n",
    "            allSeeds = readAllSeedsAsSet(seedsLocation)\n",
    "            totalCount = len(resultsPerPage)\n",
    "            allSeedsCount = len(list(allSeeds.intersection(set(resultsPerPage))))\n",
    "            extracount = totalCount - allSeedsCount\n",
    "            extraResults += extracount\n",
    "#         print(\"Results per page \" + str(resultsPerPage))\n",
    "    seedsMissed = len(testPageLocationAndSeed)-recall\n",
    "#     print(\"Seeds missed: \" + str(seedsMissed))\n",
    "#     print(\"Extra junk: \"+ str(extraResults))\n",
    "    return (patterns, seedsMissed, extraResults, len(testDirs))\n",
    "    \n",
    "# getAllPatternsByPlainStringMatch(corpusDirectory)\n",
    "\n",
    "def getPatternStore(eCommerceDataSetLocation):\n",
    "    allWebsites = getAllDirectoriesInLocation(eCommerceDataSetLocation)\n",
    "#     print(\"All websites are \" + str(allWebsites))\n",
    "    patternsStore = []\n",
    "    for website in allWebsites:\n",
    "        corpusLocation = website + \"/corpus\"\n",
    "        websiteName = os.path.basename(website)\n",
    "        (plainPatterns, plainMissed, plainJunkCount, plainTotal) = getAllPatternsByPlainStringMatch(corpusLocation)\n",
    "        (noValPatterns, noValMissed, noValJunkCount, noValTotal) = getAllPatternsByRetainingOnlyClassValue(corpusLocation)\n",
    "        if plainMissed < noValMissed:\n",
    "            patterns = (websiteName, \"plainPattern\", plainPatterns, plainMissed, plainJunkCount, plainTotal)\n",
    "#             print(plainPatterns)\n",
    "        else:\n",
    "            patterns = (websiteName, \"noValuePattern\", noValPatterns, noValMissed, noValJunkCount, noValTotal)\n",
    "        patternsStore.append(patterns)\n",
    "#     for p in patternsStore:\n",
    "#         print(p)\n",
    "    return patternsStore\n",
    "\n",
    "\n",
    "def getLastWordWithoutEqualSign(leftContext):\n",
    "    words = leftContext.strip().split(\" \")\n",
    "    totalWords = len(words)\n",
    "    if len(words)<2:\n",
    "        return \"\"\n",
    "    else:\n",
    "        if words[totalWords-1]==\"=\":\n",
    "            return words[totalWords-2]\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "def getSpecialWords(document, seedsSet):\n",
    "    totalLength = len(document)\n",
    "    specialWords = []\n",
    "    for s in seedsSet:\n",
    "        allSeedPositions = getAllStartEndPairs(document, s)\n",
    "        for (start, end) in allSeedPositions:\n",
    "            prevLoc = start-1\n",
    "            nextLoc = end\n",
    "            if prevLoc>=0 and nextLoc<totalLength:\n",
    "                prevQuot = document[prevLoc]\n",
    "                nextQuot  = document[nextLoc]\n",
    "                print(prevQuot + \" \" + nextQuot)\n",
    "                if prevQuot==\"\\\"\" and nextQuot==\"\\\"\":\n",
    "                    leftContext = document[max(0, prevLoc-100):prevLoc]\n",
    "                    lastWord = getLastWordWithoutEqualSign(leftContext)\n",
    "                    if len(lastWord)>0:\n",
    "                        specialWords.append(lastWord)\n",
    "    return specialWords\n",
    "\n",
    "\n",
    "def getAllSpecialWords(pageLocationAndSeed):\n",
    "    specialWords = []\n",
    "    specialWords.append(\"class\")\n",
    "    for (pageLocation, seeds) in pageLocationAndSeed:\n",
    "        pageContent = preprocessDocument(readPage(pageLocation))\n",
    "        specialWords.extend(getSpecialWords(pageContent, seeds))\n",
    "    specialWords = list(set(specialWords))\n",
    "    return specialWords\n",
    "\n",
    "def getAllPatternsByRetainingOnlyClassValue(corpusLocation):\n",
    "    directories             = getAllDirectoriesInLocation(corpusLocation)\n",
    "    (trainDirs, testDirs)   = trainTestSplit(directories)\n",
    "    pageLocationsAndSeed    = getPageLocationAndSeed(trainDirs)\n",
    "    testPageLocationAndSeed = getPageLocationAndSeed(testDirs)\n",
    "    specialWords = getAllSpecialWords(trainDirs)\n",
    "#     print(trainDirs)\n",
    "#     print(\"\\n===========================\\n\")\n",
    "#     for (a, b) in testPageLocationAndSeed:\n",
    "#         print(\"Page location is \" + str(a))\n",
    "#         print(\"Seeds are \" + str(b))\n",
    "#     print(\"\\n==========================\\n\")\n",
    "    leftContexts  = []\n",
    "    rightContexts = []\n",
    "    for (pageLocation, seed) in pageLocationsAndSeed:\n",
    "#         print(\"pageLocation is \" + pageLocation)\n",
    "#         print(\"seed is \")\n",
    "#         print(seed)\n",
    "        pageContent = doProcessingWithoutClass(preprocessDocument(readPage(pageLocation)), specialWords)\n",
    "        (leftContextsPerPage, rightContextsPerPage) = getContextsForAllSeeds(pageContent, seed)\n",
    "#         (leftContextsPerPage, rightContextsPerPage) = getLeftAndRightContexts(pageContent, seed)\n",
    "        leftContexts.extend(leftContextsPerPage)\n",
    "        rightContexts.extend(rightContextsPerPage)\n",
    "#     printContextInformation(leftContexts, pageLocationsAndSeed, True)\n",
    "#     printContextInformation(rightContexts, pageLocationsAndSeed)\n",
    "    leftPatterns = getLeftPatterns(leftContexts)\n",
    "    rightPatterns = getRightPatterns(rightContexts)\n",
    "    \n",
    "#     print(\"Left patterns are \" + str(leftPatterns))\n",
    "#     print(\"Right patterns are \" + str(rightPatterns))\n",
    "    patterns = allPossiblePairs(leftPatterns, rightPatterns)\n",
    "#     print(\"All possible patterns: \")\n",
    "#     print(patterns)\n",
    "    patterns = filterPatterns(pageLocationsAndSeed, patterns, True)\n",
    "    #TODO if number of patterns are empty go for empty class thing\n",
    "#     print(\"Final Patterns \")\n",
    "#     print(patterns)\n",
    "    recall = 0\n",
    "    extraResults = 0\n",
    "    for (pageLocation, seed) in testPageLocationAndSeed:\n",
    "        pageContent = doProcessingWithoutClass(preprocessDocument(readPage(pageLocation)))\n",
    "        resultsPerPage = preprocessResults(list(extractSet(patterns, pageContent)))\n",
    "#         resultsPerPage = list(set(resultsPerPage))\n",
    "        flag=True\n",
    "#         print(\"Seed wassss \" + str(seed))\n",
    "#         print(\"Results per page: \" + str(resultsPerPage))\n",
    "        for s in seed:\n",
    "            if not s in resultsPerPage:\n",
    "#                 print(\"Page location \" + str(pageLocation))\n",
    "#                 print(\"\\n\\nSeed was \" + str(s))\n",
    "                flag=False\n",
    "        if flag==True:\n",
    "            recall+=1\n",
    "#         if seed in resultsPerPage:\n",
    "#             recall += 1\n",
    "        extraElements = len(resultsPerPage) - len(seed)\n",
    "        if extraElements>1:\n",
    "            seedsLocation = os.path.dirname(pageLocation) + \"/seed\"\n",
    "            allSeeds = readAllSeedsAsSet(seedsLocation)\n",
    "#             print(\"============================\")\n",
    "#             print(\"page is \" + str(pageLocation))\n",
    "#             print(\"All seeds are\")\n",
    "#             print(allSeeds)\n",
    "#             print(\"Results per page are: \")\n",
    "#             print(resultsPerPage)\n",
    "#             print(\"============================\")\n",
    "            totalCount = len(resultsPerPage)\n",
    "            allSeedsCount = len(list(allSeeds.intersection(set(resultsPerPage))))\n",
    "            extracount = totalCount - allSeedsCount\n",
    "            extraResults += extracount\n",
    "#         print(\"Results per page \" + str(resultsPerPage))\n",
    "    seedsMissed = len(testPageLocationAndSeed)-recall\n",
    "#     print(\"Seeds missed: \" + str(seedsMissed))\n",
    "#     print(\"Extra junk: \"+ str(extraResults))\n",
    "    return (patterns, seedsMissed, extraResults, len(testDirs))\n",
    "    \n",
    "# getAllPatternsByRetainingOnlyClassValue(corpusDirectory)\n",
    "\n",
    "\n",
    "def writeListToFile(loc, l):\n",
    "    with open(loc, 'w') as f:\n",
    "        for item in l:\n",
    "            f.write(item+\"\\n\")\n",
    "\n",
    "            \n",
    "def escapeAllDoubleQuote(s):\n",
    "    return re.sub(\"\\\"\", \"\\\\\\\"\", s)\n",
    "            \n",
    "def writeSpecificationPatternsToFile(fileLocation, productPatterns):\n",
    "    header = \"GroupId\\tWebsiteName\\tPatternType\\tMissed\\tJunk\\tOutof\\tLeftPattern\\tRightPattern\"\n",
    "    groupId = 1\n",
    "    output = []\n",
    "    output.append(header)\n",
    "    for (website, pType, patterns, missed, junk, total) in productPatterns:\n",
    "        rowPrefix = str(groupId) + \"\\t\" + website + \"\\t\" + pType\n",
    "        rowPrefix+=\"\\t\" + str(missed) + \"\\t\" + str(junk) + \"\\t\" + str(total)\n",
    "        for (l, r) in patterns:\n",
    "            row = rowPrefix + \"\\t\" + l + \"\\t\" + r\n",
    "            output.append(row)\n",
    "        groupId+=1\n",
    "#     print(\"output is \")\n",
    "#     for item in output:\n",
    "#         print(item)\n",
    "    writeListToFile(fileLocation, output)\n",
    "    print(\"Output written at location: \" + fileLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter e-commerce data location: \n",
      "categoryData\n",
      "Enter outputLocation\n",
      "patternsLearnt\n",
      "Patterns will be found at patternsLearnt/categoryPatterns.tsv\n",
      "['categoryData/flipkart/corpus/page1', 'categoryData/flipkart/corpus/page6', 'categoryData/flipkart/corpus/page7', 'categoryData/flipkart/corpus/page5', 'categoryData/flipkart/corpus/page8', 'categoryData/flipkart/corpus/page3']\n",
      "['categoryData/flipkart/corpus/page1', 'categoryData/flipkart/corpus/page6', 'categoryData/flipkart/corpus/page7', 'categoryData/flipkart/corpus/page5', 'categoryData/flipkart/corpus/page8', 'categoryData/flipkart/corpus/page3']\n",
      "['categoryData/amazon/corpus/page1', 'categoryData/amazon/corpus/page6', 'categoryData/amazon/corpus/page7', 'categoryData/amazon/corpus/page5', 'categoryData/amazon/corpus/page8', 'categoryData/amazon/corpus/page3']\n",
      "['categoryData/amazon/corpus/page1', 'categoryData/amazon/corpus/page6', 'categoryData/amazon/corpus/page7', 'categoryData/amazon/corpus/page5', 'categoryData/amazon/corpus/page8', 'categoryData/amazon/corpus/page3']\n",
      "Pattern store is \n",
      "[('flipkart', 'plainPattern', [('\">', '</a><svg width=\"16\" height=\"27\" viewBox=\"0 0 16 27\" xmlns=\"http://www.w3.org/2000/svg\" class=\"_2XP0B')], 0, 0, 4), ('amazon', 'noValuePattern', [(' \\xe2\\x80\\xba </span></li> <li><span class=\"a-list-item\"> <a class=\"a-link-normal a-color-tertiary\" href=\"\"> ', ' </a> </span></li> <li class=\"a-breadcrumb-divider\"><span class=\"a-list-item a-color-tertiary\"> \\xe2\\x80\\xba ')], 0, 0, 4)]\n",
      "Output written at location: patternsLearnt/categoryPatterns.tsv\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter e-commerce data location: \")\n",
    "eCommerceDataLocation = raw_input()\n",
    "print(\"Enter outputLocation\")\n",
    "outputLocation = raw_input()\n",
    "outputLocation+=\"/categoryPatterns.tsv\"\n",
    "print(\"Patterns will be found at \" + str(outputLocation))\n",
    "patternsStore = getPatternStore(eCommerceDataLocation)\n",
    "print(\"Pattern store is \")\n",
    "print(patternsStore)\n",
    "writeSpecificationPatternsToFile(outputLocation, patternsStore)\n",
    "#categoryData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corpuss/page1', 'corpuss/page6', 'corpuss/page7', 'corpuss/page5', 'corpuss/page3']\n",
      "([('\">', '</a><svg width=\"16\" height=\"27\" viewBox=\"0 0 16 27\" xmlns=\"http://www.w3.org/2000/svg\" class=\"_2XP0B')], 0, 0, 4)\n",
      "['corpuss/page1', 'corpuss/page6', 'corpuss/page7', 'corpuss/page5', 'corpuss/page3']\n",
      "([('d=\"\" fill=\"#fff\" class=\"_24NaUy\"></path></svg></div><div class=\"_1HEvv0\"><a class=\"_1KHd47\" href=\"\">', '</a><svg width=\"\" height=\"\" viewBox=\"\" xmlns=\"http://www.w3.org/2000/svg\" class=\"_2XP0B_\"><path d=\"\"')], 1, 0, 4)\n"
     ]
    }
   ],
   "source": [
    "corpusDirectory = \"corpuss\"\n",
    "print(getAllPatternsByPlainStringMatch(corpusDirectory))\n",
    "print(getAllPatternsByRetainingOnlyClassValue(corpusDirectory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([('\">', '</')], 0, 681, 4)\n",
      "([('\">', '</')], 0, 681, 4)\n"
     ]
    }
   ],
   "source": [
    "corpusDirectory = \"corpuss\"\n",
    "print(getAllPatternsByPlainStringMatch(corpusDirectory))\n",
    "print(getAllPatternsByRetainingOnlyClassValue(corpusDirectory))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
